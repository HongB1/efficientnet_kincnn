diff --git a/DeepPhospho.py b/DeepPhospho.py
index de3fae0..2317c7e 100644
--- a/DeepPhospho.py
+++ b/DeepPhospho.py
@@ -22,6 +22,8 @@ from EarlyStopping import EarlyStopping
 import wandb
 from matplotlib import pyplot as plt
 import numpy as np
+# from utils import CosineAnnealingWarmUpRestarts
+from cosine_annealing_warmup import CosineAnnealingWarmupRestarts
 
 if __name__ == "__main__":
     config = AttrDict()
@@ -108,8 +110,9 @@ def train_model_5cv():
 
         '''optimizer & loss'''
 
-        optimizer = RAdam(model.parameters(), lr=config.defalut_learning_rate)
-        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=config.scheduler_factor, patience=config.scheduler_patience, threshold=0.0001, cooldown=0, min_lr=0, verbose=1)
+        optimizer = RAdam(model.parameters(), lr=0)
+        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=config.scheduler_factor, patience=config.scheduler_patience, threshold=0.0001, cooldown=0, min_lr=0, verbose=1)
+        scheduler = CosineAnnealingWarmupRestarts(optimizer, first_cycle_steps=50, cycle_mult=2, max_lr=0.1, min_lr=0.000001, warmup_steps=20, gamma=0.5)
         criterion = nn.BCELoss()
         # criterion = nn.CrossEntropyLoss()
         print("lr: ", optimizer.param_groups[0]['lr'])
diff --git a/code/C4_evaluation.ipynb b/code/C4_evaluation.ipynb
index 3256751..a2e6249 100644
--- a/code/C4_evaluation.ipynb
+++ b/code/C4_evaluation.ipynb
@@ -99,15 +99,509 @@
    "metadata": {},
    "outputs": [
     {
-     "ename": "AttributeError",
-     "evalue": "'NoneType' object has no attribute 'group'",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
-      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         auc_list\u001b[39m.\u001b[39mappend(\u001b[39mround\u001b[39m(auc, \u001b[39m4\u001b[39m))\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m model_list, auc_list, filedir_list\n\u001b[0;32m---> 21\u001b[0m model_list, auc_list, filedir_list \u001b[39m=\u001b[39m calculate_auc(\u001b[39m'\u001b[39;49m\u001b[39m1919\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m0520\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
-      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mcalculate_auc\u001b[0;34m(time, day, filedir)\u001b[0m\n\u001b[1;32m     12\u001b[0m auc_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m filedir \u001b[39min\u001b[39;00m filedir_list:\n\u001b[0;32m---> 14\u001b[0m     filedir_found \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msearch(\u001b[39m'\u001b[39;49m\u001b[39mDeepPP_(.+?)_\u001b[39;49m\u001b[39m'\u001b[39;49m, filedir)\u001b[39m.\u001b[39;49mgroup(\u001b[39m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m     model \u001b[39m=\u001b[39m load_multiple_model(filedir, filedir_found)\n\u001b[1;32m     16\u001b[0m     model_list\u001b[39m.\u001b[39mappend(model)\n",
-      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn1_1845_bs1024_weight0/1fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn1_1845_bs1024_weight0/2fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn1_1845_bs1024_weight0/3fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn1_1845_bs1024_weight0/4fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn1_1845_bs1024_weight0/0fold_best_model.pth\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "a13c619d048f492a9c29635b55f44dc8",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "fc051e6d5c674a43b2e9695f9b89c54c",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "0e55cec9ad9d4c23b4e7f04e73dac6c0",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "63e6a61ae7604a3e8f12423fcf3de0b7",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "ae5f5ac8ff194bd79736eaedefe5494a",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn2_1845_bs1024_weight0/1fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn2_1845_bs1024_weight0/2fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn2_1845_bs1024_weight0/3fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn2_1845_bs1024_weight0/4fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn2_1845_bs1024_weight0/0fold_best_model.pth\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "fad4a7e4b924403481ace43bcaf12f8b",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "554fc84a644343d09b548d1cacce15b0",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "01440783585347c78a20b632385e318a",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "d096b1f4655e4ed6b34748205f748449",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "8609d2217eec4bd29bf9fa2b468fbaae",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn3_1845_bs1024_weight0/1fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn3_1845_bs1024_weight0/2fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn3_1845_bs1024_weight0/3fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn3_1845_bs1024_weight0/4fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn3_1845_bs1024_weight0/0fold_best_model.pth\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "69ed44597de2481ead6889cb832fe1b1",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "7a22d8becf1e4b30a687e200a5b4e9cf",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "4914b7e4054346ad9b99af609a00ae5c",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "28f91f45f18f478186d98615dc6a6db5",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "f071773079ee445f9cedfaf978f00fb6",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn4_1845_bs1024_weight0/1fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn4_1845_bs1024_weight0/2fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn4_1845_bs1024_weight0/3fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn4_1845_bs1024_weight0/4fold_best_model.pth\n",
+      "/home/hb/python/efficientnet_kincnn/saved_model/0522/kincnn4_1845_bs1024_weight0/0fold_best_model.pth\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "bd1da66c1e394361be5fafb3c60f3f17",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "f60ad8ab7e2249f7924644f238f03fb1",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "02199ae74b314d5aa9269e78626143d6",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "2f6e848bed9f45eeb5f657c18990d37b",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
+     ]
+    },
+    {
+     "data": {
+      "application/vnd.jupyter.widget-view+json": {
+       "model_id": "1dea156af7e84d10be831922463317ce",
+       "version_major": 2,
+       "version_minor": 0
+      },
+      "text/plain": [
+       "  0%|          | 0/4 [00:00<?, ?it/s]"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([1024, 8, 9, 15])\n",
+      "torch.Size([928, 8, 9, 15])\n"
      ]
     }
    ],
@@ -119,7 +613,7 @@
     "    save_dir = f'/home/hb/python/efficientnet_kincnn/saved_model/{day}'\n",
     "\n",
     "    if not filedir :\n",
-    "        filedir_list = [f'{save_dir}/kincnn{x}_{time}_bs2048_weight0' for x in range(1, 5)]\n",
+    "        filedir_list = [f'{save_dir}/kincnn{x}_{time}_bs1024_weight0' for x in range(1, 5)]\n",
     "    else:\n",
     "        filedir_list = [f'{filedir}']\n",
     "    model_list = []\n",
@@ -132,21 +626,21 @@
     "        auc_list.append(round(auc, 4))\n",
     "    return model_list, auc_list, filedir_list\n",
     "\n",
-    "model_list, auc_list, filedir_list = calculate_auc('1919', '0520')"
+    "model_list, auc_list, filedir_list = calculate_auc('1845', '0522')"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "[0.8376, 0.8417, 0.8417, 0.8439]"
+       "[0.8398, 0.8504, 0.8504, 0.8449]"
       ]
      },
-     "execution_count": 11,
+     "execution_count": 4,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -157,7 +651,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -199,7 +693,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -213,7 +707,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [
     {
@@ -248,23 +742,143 @@
        "      <th>MBconv0_kernel_size</th>\n",
        "      <th>MBconv0_stride</th>\n",
        "      <th>...</th>\n",
-       "      <th>MBconv2_inp</th>\n",
-       "      <th>MBconv2_oup</th>\n",
-       "      <th>MBconv2_kernel_size</th>\n",
-       "      <th>MBconv2_stride</th>\n",
        "      <th>last_features</th>\n",
        "      <th>model_path</th>\n",
        "      <th>MBconv3_inp</th>\n",
        "      <th>MBconv3_oup</th>\n",
        "      <th>MBconv3_kernel_size</th>\n",
        "      <th>MBconv3_stride</th>\n",
+       "      <th>MBconv4_inp</th>\n",
+       "      <th>MBconv4_kernel_size</th>\n",
+       "      <th>MBconv4_oup</th>\n",
+       "      <th>MBconv4_stride</th>\n",
+       "    </tr>\n",
+       "  </thead>\n",
+       "  <tbody>\n",
+       "    <tr>\n",
+       "      <th>0</th>\n",
+       "      <td>56~60avg</td>\n",
+       "      <td>0.839600</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0519/DeepPP_kincnn4_0001_bs1024_weight0</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>1</th>\n",
+       "      <td>60~64avg</td>\n",
+       "      <td>0.841550</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>7920</td>\n",
+       "      <td>0519/DeepPP_kincnn4_1400_bs1024_weight0</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>2</th>\n",
+       "      <td>64~68avg</td>\n",
+       "      <td>0.837350</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>7920</td>\n",
+       "      <td>0519/DeepPP_kincnn4_1511_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(5, 5)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>3</th>\n",
+       "      <td>68~72avg</td>\n",
+       "      <td>0.843225</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>7920</td>\n",
+       "      <td>0519/DeepPP_kincnn4_1736_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(5, 3)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>4</th>\n",
+       "      <td>72~76avg</td>\n",
+       "      <td>0.843300</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0519/DeepPP_kincnn4_1847_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(5, 3)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
        "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
        "    <tr>\n",
-       "      <th>0</th>\n",
-       "      <td>56~60avg</td>\n",
-       "      <td>0.839600</td>\n",
+       "      <th>5</th>\n",
+       "      <td>76~80avg</td>\n",
+       "      <td>0.841200</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -274,21 +888,45 @@
        "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>...</td>\n",
-       "      <td>32</td>\n",
-       "      <td>64</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0520/DeepPP_kincnn4_0039_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>6</th>\n",
+       "      <td>80~84avg</td>\n",
+       "      <td>0.841225</td>\n",
        "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
        "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
        "      <td>3960</td>\n",
-       "      <td>0519/DeepPP_kincnn4_0001_bs1024_weight0</td>\n",
+       "      <td>0520/DeepPP_kincnn4_1757_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(3, 3)</td>\n",
+       "      <td>(1, 1)</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>1</th>\n",
-       "      <td>60~64avg</td>\n",
-       "      <td>0.841550</td>\n",
+       "      <th>7</th>\n",
+       "      <td>84~88avg</td>\n",
+       "      <td>0.844575</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -298,21 +936,21 @@
        "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>...</td>\n",
-       "      <td>32</td>\n",
-       "      <td>64</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0520/DeepPP_kincnn4_1835_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
-       "      <td>7920</td>\n",
-       "      <td>0519/DeepPP_kincnn4_1400_bs1024_weight0</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>2</th>\n",
-       "      <td>64~68avg</td>\n",
-       "      <td>0.837350</td>\n",
+       "      <th>8</th>\n",
+       "      <td>88~92avg</td>\n",
+       "      <td>0.836575</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -322,21 +960,45 @@
        "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>...</td>\n",
-       "      <td>32</td>\n",
-       "      <td>64</td>\n",
+       "      <td>2040</td>\n",
+       "      <td>0520/kincnn4_1919_bs2048_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>9</th>\n",
+       "      <td>92~96avg</td>\n",
+       "      <td>0.838175</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
-       "      <td>7920</td>\n",
-       "      <td>0519/DeepPP_kincnn4_1511_bs1024_weight0</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0521/kincnn4_1617_bs2048_weight0</td>\n",
        "      <td>64.0</td>\n",
        "      <td>128.0</td>\n",
-       "      <td>(5, 5)</td>\n",
+       "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>3</th>\n",
-       "      <td>68~72avg</td>\n",
-       "      <td>0.843225</td>\n",
+       "      <th>10</th>\n",
+       "      <td>96~100avg</td>\n",
+       "      <td>0.837200</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -346,22 +1008,46 @@
        "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>...</td>\n",
-       "      <td>32</td>\n",
-       "      <td>64</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0521/kincnn4_1656_bs2048_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
-       "      <td>7920</td>\n",
-       "      <td>0519/DeepPP_kincnn4_1736_bs1024_weight0</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>11</th>\n",
+       "      <td>100~104avg</td>\n",
+       "      <td>0.835850</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0521/kincnn4_1733_bs2048_weight0</td>\n",
        "      <td>64.0</td>\n",
        "      <td>128.0</td>\n",
-       "      <td>(5, 3)</td>\n",
+       "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>4</th>\n",
-       "      <td>72~76avg</td>\n",
-       "      <td>0.843300</td>\n",
-       "      <td>(3, 1)</td>\n",
+       "      <th>12</th>\n",
+       "      <td>104~108avg</td>\n",
+       "      <td>0.840200</td>\n",
+       "      <td>(7, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
        "      <td>(2, 1)</td>\n",
@@ -370,21 +1056,45 @@
        "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>...</td>\n",
-       "      <td>32</td>\n",
-       "      <td>64</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0521/kincnn4_1820_bs2048_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>13</th>\n",
+       "      <td>108~112avg</td>\n",
+       "      <td>0.844575</td>\n",
        "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
        "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
        "      <td>3960</td>\n",
-       "      <td>0519/DeepPP_kincnn4_1847_bs1024_weight0</td>\n",
+       "      <td>0521/kincnn4_1905_bs1024_weight0</td>\n",
        "      <td>64.0</td>\n",
        "      <td>128.0</td>\n",
-       "      <td>(5, 3)</td>\n",
+       "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>5</th>\n",
-       "      <td>76~80avg</td>\n",
-       "      <td>0.841200</td>\n",
+       "      <th>14</th>\n",
+       "      <td>112~116avg</td>\n",
+       "      <td>0.844575</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -394,105 +1104,309 @@
        "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>...</td>\n",
-       "      <td>32</td>\n",
-       "      <td>64</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0521/kincnn4_1905_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
        "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>15</th>\n",
+       "      <td>116~120avg</td>\n",
+       "      <td>0.835500</td>\n",
+       "      <td>(7, 3)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
        "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
        "      <td>3960</td>\n",
-       "      <td>0520/DeepPP_kincnn4_0039_bs1024_weight0</td>\n",
+       "      <td>0522/kincnn4_1411_bs1024_weight0</td>\n",
        "      <td>64.0</td>\n",
        "      <td>128.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>16</th>\n",
+       "      <td>120~124avg</td>\n",
+       "      <td>0.837775</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>8</td>\n",
        "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>3960</td>\n",
+       "      <td>0522/kincnn4_1449_bs1024_weight0</td>\n",
+       "      <td>16.0</td>\n",
+       "      <td>32.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
+       "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>6</th>\n",
-       "      <td>80~84avg</td>\n",
-       "      <td>0.841225</td>\n",
+       "      <th>17</th>\n",
+       "      <td>124~128avg</td>\n",
+       "      <td>0.835750</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
        "      <td>(2, 1)</td>\n",
        "      <td>8</td>\n",
-       "      <td>16</td>\n",
+       "      <td>8</td>\n",
        "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>...</td>\n",
-       "      <td>32</td>\n",
-       "      <td>64</td>\n",
+       "      <td>2040</td>\n",
+       "      <td>0522/kincnn4_1528_bs1024_weight0</td>\n",
+       "      <td>16.0</td>\n",
+       "      <td>32.0</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>32.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>18</th>\n",
+       "      <td>128~132avg</td>\n",
+       "      <td>0.841325</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>8</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>1080</td>\n",
+       "      <td>0522/kincnn4_1607_bs1024_weight0</td>\n",
+       "      <td>32.0</td>\n",
+       "      <td>64.0</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(2, 1)</td>\n",
-       "      <td>3960</td>\n",
-       "      <td>0520/DeepPP_kincnn4_1757_bs1024_weight0</td>\n",
        "      <td>64.0</td>\n",
+       "      <td>(3, 1)</td>\n",
        "      <td>128.0</td>\n",
-       "      <td>(3, 3)</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>19</th>\n",
+       "      <td>132~136avg</td>\n",
+       "      <td>0.850800</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>1080</td>\n",
+       "      <td>0522/kincnn4_1734_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>256.0</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "    </tr>\n",
+       "    <tr>\n",
+       "      <th>20</th>\n",
+       "      <td>136~140avg</td>\n",
+       "      <td>0.851825</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(1, 1)</td>\n",
+       "      <td>True</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>8</td>\n",
+       "      <td>16</td>\n",
+       "      <td>(5, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
+       "      <td>...</td>\n",
+       "      <td>1080</td>\n",
+       "      <td>0522/kincnn4_1805_bs1024_weight0</td>\n",
+       "      <td>64.0</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>(2, 1)</td>\n",
+       "      <td>128.0</td>\n",
+       "      <td>(3, 1)</td>\n",
+       "      <td>256.0</td>\n",
+       "      <td>(2, 1)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
-       "<p>7 rows × 24 columns</p>\n",
+       "<p>21 rows × 28 columns</p>\n",
        "</div>"
       ],
       "text/plain": [
-       "       data       AUC conv_stem_kernel_size conv_stem_stride_size  \\\n",
-       "0  56~60avg  0.839600                (3, 1)                (1, 1)   \n",
-       "1  60~64avg  0.841550                (3, 1)                (1, 1)   \n",
-       "2  64~68avg  0.837350                (3, 1)                (1, 1)   \n",
-       "3  68~72avg  0.843225                (3, 1)                (1, 1)   \n",
-       "4  72~76avg  0.843300                (3, 1)                (1, 1)   \n",
-       "5  76~80avg  0.841200                (3, 1)                (1, 1)   \n",
-       "6  80~84avg  0.841225                (3, 1)                (1, 1)   \n",
+       "          data       AUC conv_stem_kernel_size conv_stem_stride_size  \\\n",
+       "0     56~60avg  0.839600                (3, 1)                (1, 1)   \n",
+       "1     60~64avg  0.841550                (3, 1)                (1, 1)   \n",
+       "2     64~68avg  0.837350                (3, 1)                (1, 1)   \n",
+       "3     68~72avg  0.843225                (3, 1)                (1, 1)   \n",
+       "4     72~76avg  0.843300                (3, 1)                (1, 1)   \n",
+       "5     76~80avg  0.841200                (3, 1)                (1, 1)   \n",
+       "6     80~84avg  0.841225                (3, 1)                (1, 1)   \n",
+       "7     84~88avg  0.844575                (3, 1)                (1, 1)   \n",
+       "8     88~92avg  0.836575                (3, 1)                (1, 1)   \n",
+       "9     92~96avg  0.838175                (3, 1)                (1, 1)   \n",
+       "10   96~100avg  0.837200                (3, 1)                (1, 1)   \n",
+       "11  100~104avg  0.835850                (3, 1)                (1, 1)   \n",
+       "12  104~108avg  0.840200                (7, 1)                (1, 1)   \n",
+       "13  108~112avg  0.844575                (3, 1)                (1, 1)   \n",
+       "14  112~116avg  0.844575                (3, 1)                (1, 1)   \n",
+       "15  116~120avg  0.835500                (7, 3)                (1, 1)   \n",
+       "16  120~124avg  0.837775                (3, 1)                (1, 1)   \n",
+       "17  124~128avg  0.835750                (3, 1)                (1, 1)   \n",
+       "18  128~132avg  0.841325                (3, 1)                (1, 1)   \n",
+       "19  132~136avg  0.850800                (3, 1)                (1, 1)   \n",
+       "20  136~140avg  0.851825                (3, 1)                (1, 1)   \n",
        "\n",
-       "   conv_stem_pooling conv_stem_pooling_kernel_size  MBconv0_inp  MBconv0_oup  \\\n",
-       "0               True                        (2, 1)            8           16   \n",
-       "1               True                        (2, 1)            8           16   \n",
-       "2               True                        (2, 1)            8           16   \n",
-       "3               True                        (2, 1)            8           16   \n",
-       "4               True                        (2, 1)            8           16   \n",
-       "5               True                        (2, 1)            8           16   \n",
-       "6               True                        (2, 1)            8           16   \n",
+       "    conv_stem_pooling conv_stem_pooling_kernel_size  MBconv0_inp  MBconv0_oup  \\\n",
+       "0                True                        (2, 1)            8           16   \n",
+       "1                True                        (2, 1)            8           16   \n",
+       "2                True                        (2, 1)            8           16   \n",
+       "3                True                        (2, 1)            8           16   \n",
+       "4                True                        (2, 1)            8           16   \n",
+       "5                True                        (2, 1)            8           16   \n",
+       "6                True                        (2, 1)            8           16   \n",
+       "7                True                        (2, 1)            8           16   \n",
+       "8                True                        (2, 1)            8           16   \n",
+       "9                True                        (2, 1)            8           16   \n",
+       "10               True                        (2, 1)            8           16   \n",
+       "11               True                        (2, 1)            8           16   \n",
+       "12               True                        (2, 1)            8           16   \n",
+       "13               True                        (2, 1)            8           16   \n",
+       "14               True                        (2, 1)            8           16   \n",
+       "15               True                        (2, 1)            8           16   \n",
+       "16               True                        (2, 1)            8            8   \n",
+       "17               True                        (2, 1)            8            8   \n",
+       "18               True                        (2, 1)            8            8   \n",
+       "19               True                        (2, 1)            8           16   \n",
+       "20               True                        (2, 1)            8           16   \n",
        "\n",
-       "  MBconv0_kernel_size MBconv0_stride  ...  MBconv2_inp  MBconv2_oup  \\\n",
-       "0              (5, 1)         (1, 1)  ...           32           64   \n",
-       "1              (5, 1)         (1, 1)  ...           32           64   \n",
-       "2              (5, 1)         (1, 1)  ...           32           64   \n",
-       "3              (5, 1)         (1, 1)  ...           32           64   \n",
-       "4              (5, 1)         (1, 1)  ...           32           64   \n",
-       "5              (5, 1)         (1, 1)  ...           32           64   \n",
-       "6              (5, 1)         (1, 1)  ...           32           64   \n",
+       "   MBconv0_kernel_size MBconv0_stride  ...  last_features  \\\n",
+       "0               (5, 1)         (1, 1)  ...           3960   \n",
+       "1               (5, 1)         (1, 1)  ...           7920   \n",
+       "2               (5, 1)         (1, 1)  ...           7920   \n",
+       "3               (5, 1)         (1, 1)  ...           7920   \n",
+       "4               (5, 1)         (1, 1)  ...           3960   \n",
+       "5               (5, 1)         (1, 1)  ...           3960   \n",
+       "6               (5, 1)         (1, 1)  ...           3960   \n",
+       "7               (5, 1)         (1, 1)  ...           3960   \n",
+       "8               (5, 1)         (1, 1)  ...           2040   \n",
+       "9               (5, 1)         (1, 1)  ...           3960   \n",
+       "10              (5, 1)         (1, 1)  ...           3960   \n",
+       "11              (5, 1)         (1, 1)  ...           3960   \n",
+       "12              (5, 1)         (1, 1)  ...           3960   \n",
+       "13              (5, 1)         (1, 1)  ...           3960   \n",
+       "14              (5, 1)         (1, 1)  ...           3960   \n",
+       "15              (5, 1)         (1, 1)  ...           3960   \n",
+       "16              (5, 1)         (1, 1)  ...           3960   \n",
+       "17              (5, 1)         (1, 1)  ...           2040   \n",
+       "18              (5, 1)         (1, 1)  ...           1080   \n",
+       "19              (5, 1)         (1, 1)  ...           1080   \n",
+       "20              (5, 1)         (1, 1)  ...           1080   \n",
        "\n",
-       "  MBconv2_kernel_size MBconv2_stride  last_features  \\\n",
-       "0              (3, 1)         (2, 1)           3960   \n",
-       "1              (3, 1)         (1, 1)           7920   \n",
-       "2              (3, 1)         (1, 1)           7920   \n",
-       "3              (3, 1)         (1, 1)           7920   \n",
-       "4              (3, 1)         (2, 1)           3960   \n",
-       "5              (3, 1)         (2, 1)           3960   \n",
-       "6              (3, 1)         (2, 1)           3960   \n",
+       "                                 model_path MBconv3_inp MBconv3_oup  \\\n",
+       "0   0519/DeepPP_kincnn4_0001_bs1024_weight0         NaN         NaN   \n",
+       "1   0519/DeepPP_kincnn4_1400_bs1024_weight0         NaN         NaN   \n",
+       "2   0519/DeepPP_kincnn4_1511_bs1024_weight0        64.0       128.0   \n",
+       "3   0519/DeepPP_kincnn4_1736_bs1024_weight0        64.0       128.0   \n",
+       "4   0519/DeepPP_kincnn4_1847_bs1024_weight0        64.0       128.0   \n",
+       "5   0520/DeepPP_kincnn4_0039_bs1024_weight0        64.0       128.0   \n",
+       "6   0520/DeepPP_kincnn4_1757_bs1024_weight0        64.0       128.0   \n",
+       "7   0520/DeepPP_kincnn4_1835_bs1024_weight0        64.0       128.0   \n",
+       "8          0520/kincnn4_1919_bs2048_weight0        64.0       128.0   \n",
+       "9          0521/kincnn4_1617_bs2048_weight0        64.0       128.0   \n",
+       "10         0521/kincnn4_1656_bs2048_weight0        64.0       128.0   \n",
+       "11         0521/kincnn4_1733_bs2048_weight0        64.0       128.0   \n",
+       "12         0521/kincnn4_1820_bs2048_weight0        64.0       128.0   \n",
+       "13         0521/kincnn4_1905_bs1024_weight0        64.0       128.0   \n",
+       "14         0521/kincnn4_1905_bs1024_weight0        64.0       128.0   \n",
+       "15         0522/kincnn4_1411_bs1024_weight0        64.0       128.0   \n",
+       "16         0522/kincnn4_1449_bs1024_weight0        16.0        32.0   \n",
+       "17         0522/kincnn4_1528_bs1024_weight0        16.0        32.0   \n",
+       "18         0522/kincnn4_1607_bs1024_weight0        32.0        64.0   \n",
+       "19         0522/kincnn4_1734_bs1024_weight0        64.0       128.0   \n",
+       "20         0522/kincnn4_1805_bs1024_weight0        64.0       128.0   \n",
        "\n",
-       "                                model_path MBconv3_inp MBconv3_oup  \\\n",
-       "0  0519/DeepPP_kincnn4_0001_bs1024_weight0         NaN         NaN   \n",
-       "1  0519/DeepPP_kincnn4_1400_bs1024_weight0         NaN         NaN   \n",
-       "2  0519/DeepPP_kincnn4_1511_bs1024_weight0        64.0       128.0   \n",
-       "3  0519/DeepPP_kincnn4_1736_bs1024_weight0        64.0       128.0   \n",
-       "4  0519/DeepPP_kincnn4_1847_bs1024_weight0        64.0       128.0   \n",
-       "5  0520/DeepPP_kincnn4_0039_bs1024_weight0        64.0       128.0   \n",
-       "6  0520/DeepPP_kincnn4_1757_bs1024_weight0        64.0       128.0   \n",
+       "    MBconv3_kernel_size  MBconv3_stride MBconv4_inp MBconv4_kernel_size  \\\n",
+       "0                   NaN             NaN         NaN                 NaN   \n",
+       "1                   NaN             NaN         NaN                 NaN   \n",
+       "2                (5, 5)          (1, 1)         NaN                 NaN   \n",
+       "3                (5, 3)          (1, 1)         NaN                 NaN   \n",
+       "4                (5, 3)          (1, 1)         NaN                 NaN   \n",
+       "5                (5, 1)          (1, 1)         NaN                 NaN   \n",
+       "6                (3, 3)          (1, 1)         NaN                 NaN   \n",
+       "7                (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "8                (3, 1)          (2, 1)         NaN                 NaN   \n",
+       "9                (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "10               (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "11               (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "12               (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "13               (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "14               (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "15               (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "16               (3, 1)          (1, 1)         NaN                 NaN   \n",
+       "17               (5, 1)          (2, 1)        32.0              (3, 1)   \n",
+       "18               (3, 1)          (2, 1)        64.0              (3, 1)   \n",
+       "19               (3, 1)          (2, 1)       128.0              (3, 1)   \n",
+       "20               (3, 1)          (2, 1)       128.0              (3, 1)   \n",
        "\n",
-       "   MBconv3_kernel_size MBconv3_stride  \n",
-       "0                  NaN            NaN  \n",
-       "1                  NaN            NaN  \n",
-       "2               (5, 5)         (1, 1)  \n",
-       "3               (5, 3)         (1, 1)  \n",
-       "4               (5, 3)         (1, 1)  \n",
-       "5               (5, 1)         (1, 1)  \n",
-       "6               (3, 3)         (1, 1)  \n",
+       "    MBconv4_oup MBconv4_stride  \n",
+       "0           NaN            NaN  \n",
+       "1           NaN            NaN  \n",
+       "2           NaN            NaN  \n",
+       "3           NaN            NaN  \n",
+       "4           NaN            NaN  \n",
+       "5           NaN            NaN  \n",
+       "6           NaN            NaN  \n",
+       "7           NaN            NaN  \n",
+       "8           NaN            NaN  \n",
+       "9           NaN            NaN  \n",
+       "10          NaN            NaN  \n",
+       "11          NaN            NaN  \n",
+       "12          NaN            NaN  \n",
+       "13          NaN            NaN  \n",
+       "14          NaN            NaN  \n",
+       "15          NaN            NaN  \n",
+       "16          NaN            NaN  \n",
+       "17         64.0         (2, 1)  \n",
+       "18        128.0         (2, 1)  \n",
+       "19        256.0         (2, 1)  \n",
+       "20        256.0         (2, 1)  \n",
        "\n",
-       "[7 rows x 24 columns]"
+       "[21 rows x 28 columns]"
       ]
      },
-     "execution_count": 14,
+     "execution_count": 7,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -503,7 +1417,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 8,
    "metadata": {},
    "outputs": [
     {
@@ -696,9 +1610,9 @@
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>71</th>\n",
+       "      <th>135</th>\n",
        "      <td>train4</td>\n",
-       "      <td>0.8463</td>\n",
+       "      <td>0.8497</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -720,9 +1634,9 @@
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>72</th>\n",
+       "      <th>136</th>\n",
        "      <td>train1</td>\n",
-       "      <td>0.8426</td>\n",
+       "      <td>0.8481</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -744,9 +1658,9 @@
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>73</th>\n",
+       "      <th>137</th>\n",
        "      <td>train2</td>\n",
-       "      <td>0.8438</td>\n",
+       "      <td>0.8532</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -768,9 +1682,9 @@
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>74</th>\n",
+       "      <th>138</th>\n",
        "      <td>train3</td>\n",
-       "      <td>0.8438</td>\n",
+       "      <td>0.8532</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -792,9 +1706,9 @@
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <th>75</th>\n",
+       "      <th>139</th>\n",
        "      <td>train4</td>\n",
-       "      <td>0.8430</td>\n",
+       "      <td>0.8528</td>\n",
        "      <td>(3, 1)</td>\n",
        "      <td>(1, 1)</td>\n",
        "      <td>True</td>\n",
@@ -817,92 +1731,92 @@
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
-       "<p>76 rows × 72 columns</p>\n",
+       "<p>140 rows × 72 columns</p>\n",
        "</div>"
       ],
       "text/plain": [
-       "      data     AUC conv_stem_kernel_size conv_stem_stride_size  \\\n",
-       "0   train1  0.8273                (3, 1)                (1, 1)   \n",
-       "1   train1  0.8202                (3, 1)                (1, 1)   \n",
-       "2   train1  0.8243                (3, 1)                (1, 1)   \n",
-       "3   train1  0.8262                (3, 1)                (1, 1)   \n",
-       "4   train1  0.6549                (3, 1)                (1, 1)   \n",
-       "..     ...     ...                   ...                   ...   \n",
-       "71  train4  0.8463                (3, 1)                (1, 1)   \n",
-       "72  train1  0.8426                (3, 1)                (1, 1)   \n",
-       "73  train2  0.8438                (3, 1)                (1, 1)   \n",
-       "74  train3  0.8438                (3, 1)                (1, 1)   \n",
-       "75  train4  0.8430                (3, 1)                (1, 1)   \n",
+       "       data     AUC conv_stem_kernel_size conv_stem_stride_size  \\\n",
+       "0    train1  0.8273                (3, 1)                (1, 1)   \n",
+       "1    train1  0.8202                (3, 1)                (1, 1)   \n",
+       "2    train1  0.8243                (3, 1)                (1, 1)   \n",
+       "3    train1  0.8262                (3, 1)                (1, 1)   \n",
+       "4    train1  0.6549                (3, 1)                (1, 1)   \n",
+       "..      ...     ...                   ...                   ...   \n",
+       "135  train4  0.8497                (3, 1)                (1, 1)   \n",
+       "136  train1  0.8481                (3, 1)                (1, 1)   \n",
+       "137  train2  0.8532                (3, 1)                (1, 1)   \n",
+       "138  train3  0.8532                (3, 1)                (1, 1)   \n",
+       "139  train4  0.8528                (3, 1)                (1, 1)   \n",
        "\n",
-       "    conv_stem_pooling conv_stem_pooling_kernel_size  MBconv0_inp  MBconv0_oup  \\\n",
-       "0                True                        (2, 1)            8           16   \n",
-       "1                True                        (2, 1)            8           16   \n",
-       "2                True                        (2, 1)            8           16   \n",
-       "3                True                        (2, 1)            8           16   \n",
-       "4                True                        (2, 1)            8            8   \n",
-       "..                ...                           ...          ...          ...   \n",
-       "71               True                        (2, 1)            8           16   \n",
-       "72               True                        (2, 1)            8           16   \n",
-       "73               True                        (2, 1)            8           16   \n",
-       "74               True                        (2, 1)            8           16   \n",
-       "75               True                        (2, 1)            8           16   \n",
+       "     conv_stem_pooling conv_stem_pooling_kernel_size  MBconv0_inp  \\\n",
+       "0                 True                        (2, 1)            8   \n",
+       "1                 True                        (2, 1)            8   \n",
+       "2                 True                        (2, 1)            8   \n",
+       "3                 True                        (2, 1)            8   \n",
+       "4                 True                        (2, 1)            8   \n",
+       "..                 ...                           ...          ...   \n",
+       "135               True                        (2, 1)            8   \n",
+       "136               True                        (2, 1)            8   \n",
+       "137               True                        (2, 1)            8   \n",
+       "138               True                        (2, 1)            8   \n",
+       "139               True                        (2, 1)            8   \n",
        "\n",
-       "   MBconv0_kernel_size MBconv0_stride  ...  MBconv13_kernel_size  \\\n",
-       "0               (3, 1)         (1, 1)  ...                   NaN   \n",
-       "1               (5, 5)         (2, 1)  ...                   NaN   \n",
-       "2               (5, 3)         (2, 1)  ...                   NaN   \n",
-       "3               (5, 1)         (2, 1)  ...                   NaN   \n",
-       "4               (3, 3)         (1, 1)  ...                (5, 5)   \n",
-       "..                 ...            ...  ...                   ...   \n",
-       "71              (5, 1)         (1, 1)  ...                   NaN   \n",
-       "72              (5, 1)         (1, 1)  ...                   NaN   \n",
-       "73              (5, 1)         (1, 1)  ...                   NaN   \n",
-       "74              (5, 1)         (1, 1)  ...                   NaN   \n",
-       "75              (5, 1)         (1, 1)  ...                   NaN   \n",
+       "     MBconv0_oup MBconv0_kernel_size MBconv0_stride  ...  \\\n",
+       "0             16              (3, 1)         (1, 1)  ...   \n",
+       "1             16              (5, 5)         (2, 1)  ...   \n",
+       "2             16              (5, 3)         (2, 1)  ...   \n",
+       "3             16              (5, 1)         (2, 1)  ...   \n",
+       "4              8              (3, 3)         (1, 1)  ...   \n",
+       "..           ...                 ...            ...  ...   \n",
+       "135           16              (5, 1)         (1, 1)  ...   \n",
+       "136           16              (5, 1)         (1, 1)  ...   \n",
+       "137           16              (5, 1)         (1, 1)  ...   \n",
+       "138           16              (5, 1)         (1, 1)  ...   \n",
+       "139           16              (5, 1)         (1, 1)  ...   \n",
        "\n",
-       "   MBconv13_stride  MBconv14_inp  MBconv14_oup MBconv14_kernel_size  \\\n",
-       "0              NaN           NaN           NaN                  NaN   \n",
-       "1              NaN           NaN           NaN                  NaN   \n",
-       "2              NaN           NaN           NaN                  NaN   \n",
-       "3              NaN           NaN           NaN                  NaN   \n",
-       "4           (1, 1)         720.0         120.0               (5, 5)   \n",
-       "..             ...           ...           ...                  ...   \n",
-       "71             NaN           NaN           NaN                  NaN   \n",
-       "72             NaN           NaN           NaN                  NaN   \n",
-       "73             NaN           NaN           NaN                  NaN   \n",
-       "74             NaN           NaN           NaN                  NaN   \n",
-       "75             NaN           NaN           NaN                  NaN   \n",
+       "     MBconv13_kernel_size MBconv13_stride  MBconv14_inp  MBconv14_oup  \\\n",
+       "0                     NaN             NaN           NaN           NaN   \n",
+       "1                     NaN             NaN           NaN           NaN   \n",
+       "2                     NaN             NaN           NaN           NaN   \n",
+       "3                     NaN             NaN           NaN           NaN   \n",
+       "4                  (5, 5)          (1, 1)         720.0         120.0   \n",
+       "..                    ...             ...           ...           ...   \n",
+       "135                   NaN             NaN           NaN           NaN   \n",
+       "136                   NaN             NaN           NaN           NaN   \n",
+       "137                   NaN             NaN           NaN           NaN   \n",
+       "138                   NaN             NaN           NaN           NaN   \n",
+       "139                   NaN             NaN           NaN           NaN   \n",
        "\n",
-       "   MBconv14_stride  MBconv15_inp  MBconv15_oup MBconv15_kernel_size  \\\n",
-       "0              NaN           NaN           NaN                  NaN   \n",
-       "1              NaN           NaN           NaN                  NaN   \n",
-       "2              NaN           NaN           NaN                  NaN   \n",
-       "3              NaN           NaN           NaN                  NaN   \n",
-       "4           (1, 1)         720.0         200.0               (3, 3)   \n",
-       "..             ...           ...           ...                  ...   \n",
-       "71             NaN           NaN           NaN                  NaN   \n",
-       "72             NaN           NaN           NaN                  NaN   \n",
-       "73             NaN           NaN           NaN                  NaN   \n",
-       "74             NaN           NaN           NaN                  NaN   \n",
-       "75             NaN           NaN           NaN                  NaN   \n",
+       "    MBconv14_kernel_size MBconv14_stride  MBconv15_inp  MBconv15_oup  \\\n",
+       "0                    NaN             NaN           NaN           NaN   \n",
+       "1                    NaN             NaN           NaN           NaN   \n",
+       "2                    NaN             NaN           NaN           NaN   \n",
+       "3                    NaN             NaN           NaN           NaN   \n",
+       "4                 (5, 5)          (1, 1)         720.0         200.0   \n",
+       "..                   ...             ...           ...           ...   \n",
+       "135                  NaN             NaN           NaN           NaN   \n",
+       "136                  NaN             NaN           NaN           NaN   \n",
+       "137                  NaN             NaN           NaN           NaN   \n",
+       "138                  NaN             NaN           NaN           NaN   \n",
+       "139                  NaN             NaN           NaN           NaN   \n",
        "\n",
-       "   MBconv15_stride  \n",
-       "0              NaN  \n",
-       "1              NaN  \n",
-       "2              NaN  \n",
-       "3              NaN  \n",
-       "4           (1, 1)  \n",
-       "..             ...  \n",
-       "71             NaN  \n",
-       "72             NaN  \n",
-       "73             NaN  \n",
-       "74             NaN  \n",
-       "75             NaN  \n",
+       "    MBconv15_kernel_size MBconv15_stride  \n",
+       "0                    NaN             NaN  \n",
+       "1                    NaN             NaN  \n",
+       "2                    NaN             NaN  \n",
+       "3                    NaN             NaN  \n",
+       "4                 (3, 3)          (1, 1)  \n",
+       "..                   ...             ...  \n",
+       "135                  NaN             NaN  \n",
+       "136                  NaN             NaN  \n",
+       "137                  NaN             NaN  \n",
+       "138                  NaN             NaN  \n",
+       "139                  NaN             NaN  \n",
        "\n",
-       "[76 rows x 72 columns]"
+       "[140 rows x 72 columns]"
       ]
      },
-     "execution_count": 9,
+     "execution_count": 8,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -21266,7 +22180,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.10.9"
+   "version": "3.10.4"
   },
   "orig_nbformat": 4,
   "vscode": {
diff --git a/code/model_info.xlsx b/code/model_info.xlsx
index d156840..98d4a78 100644
Binary files a/code/model_info.xlsx and b/code/model_info.xlsx differ
diff --git a/gpu_0.sh b/gpu_0.sh
deleted file mode 100755
index f1a7e97..0000000
--- a/gpu_0.sh
+++ /dev/null
@@ -1,30 +0,0 @@
-#!/bin/bash
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-B 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-C 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 9 Natural Normalize 512 500 1e-3 5 7 0.5 25 
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 10 Natural Normalize 512 500 1e-3 5 7 0.5 25
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-C 9 Natural Normalize 512 500 1e-3df_test_st 5 7 0.5 25 
-#     config.gpu_num = sys.argv[1]
-#     config.batch_size = int(sys.argv[2])
-#     config.n_epoch = int(sys.argv[3])
-#     config.defalut_learning_rate = float(sys.argv[4])
-#     config.fold_num = int(sys.argv[5])
-#     config.scheduler_patience, config.scheduler_factor = int(sys.argv[6]), float(sys.argv[7])
-#     config.erls_patience = int(sys.argv[8])
-#     config.dataset = sys.argv[9]
-#     config.pretrain_fold_num = sys.argv[10]
-#     config.model = f'efficientnet-phospho-B-15'
-#     config.save_dir = f'/home/hb/python/efficientnet_kincnn/saved_model/{datetime.today().strftime("%m%d")}/DeepPP_{config.dataset}_{datetime.today().strftime("%H%M")}_bs{config.batch_size}_weight{config.pretrain_fold_num}'
-python3 /home/hb/python/efficientnet_kincnn/DeepPhospho.py 0 2048 500 1e-3 5 7 0.7 50 kincnn1 0
-
-
diff --git a/gpu_1.sh b/gpu_1.sh
deleted file mode 100755
index 7e627a8..0000000
--- a/gpu_1.sh
+++ /dev/null
@@ -1,30 +0,0 @@
-#!/bin/bash
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-B 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-C 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 9 Natural Normalize 512 500 1e-3 5 7 0.5 25 
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 10 Natural Normalize 512 500 1e-3 5 7 0.5 25
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-C 9 Natural Normalize 512 500 1e-3df_test_st 5 7 0.5 25 
-#     config.gpu_num = sys.argv[1]
-#     config.batch_size = int(sys.argv[2])
-#     config.n_epoch = int(sys.argv[3])
-#     config.defalut_learning_rate = float(sys.argv[4])
-#     config.fold_num = int(sys.argv[5])
-#     config.scheduler_patience, config.scheduler_factor = int(sys.argv[6]), float(sys.argv[7])
-#     config.erls_patience = int(sys.argv[8])
-#     config.dataset = sys.argv[9]
-#     config.pretrain_fold_num = sys.argv[10]
-#     config.model = f'efficientnet-phospho-B-15'
-#     config.save_dir = f'/home/hb/python/efficientnet_kincnn/saved_model/{datetime.today().strftime("%m%d")}/DeepPP_{config.dataset}_{datetime.today().strftime("%H%M")}_bs{config.batch_size}_weight{config.pretrain_fold_num}'
-python3 /home/hb/python/efficientnet_kincnn/DeepPhospho2.py 1 2048 500 1e-3 5 7 0.7 50 kincnn2 0
-
-
diff --git a/gpu_2.sh b/gpu_2.sh
deleted file mode 100755
index 05210d3..0000000
--- a/gpu_2.sh
+++ /dev/null
@@ -1,30 +0,0 @@
-#!/bin/bash
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-B 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-C 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 9 Natural Normalize 512 500 1e-3 5 7 0.5 25 
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 10 Natural Normalize 512 500 1e-3 5 7 0.5 25
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-C 9 Natural Normalize 512 500 1e-3df_test_st 5 7 0.5 25 
-#     config.gpu_num = sys.argv[1]
-#     config.batch_size = int(sys.argv[2])
-#     config.n_epoch = int(sys.argv[3])
-#     config.defalut_learning_rate = float(sys.argv[4])
-#     config.fold_num = int(sys.argv[5])
-#     config.scheduler_patience, config.scheduler_factor = int(sys.argv[6]), float(sys.argv[7])
-#     config.erls_patience = int(sys.argv[8])
-#     config.dataset = sys.argv[9]
-#     config.pretrain_fold_num = sys.argv[10]
-#     config.model = f'efficientnet-phospho-B-15'
-#     config.save_dir = f'/home/hb/python/efficientnet_kincnn/saved_model/{datetime.today().strftime("%m%d")}/DeepPP_{config.dataset}_{datetime.today().strftime("%H%M")}_bs{config.batch_size}_weight{config.pretrain_fold_num}'
-python3 /home/hb/python/efficientnet_kincnn/DeepPhospho3.py 2 2048 500 1e-3 5 7 0.7 50 kincnn3 0
-
-
diff --git a/gpu_3.sh b/gpu_3.sh
deleted file mode 100755
index f78a5e4..0000000
--- a/gpu_3.sh
+++ /dev/null
@@ -1,30 +0,0 @@
-#!/bin/bash
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-B 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-C 9 Natural log 512 500 1e-3 5 7 0.5 25 
-
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 9 Natural Normalize 512 500 1e-3 5 7 0.5 25 
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-A 10 Natural Normalize 512 500 1e-3 5 7 0.5 25
-
-# python /home/hb/neoantigen/code/DeepNeo_.py 0 HLA-C 9 Natural Normalize 512 500 1e-3df_test_st 5 7 0.5 25 
-#     config.gpu_num = sys.argv[1]
-#     config.batch_size = int(sys.argv[2])
-#     config.n_epoch = int(sys.argv[3])
-#     config.defalut_learning_rate = float(sys.argv[4])
-#     config.fold_num = int(sys.argv[5])
-#     config.scheduler_patience, config.scheduler_factor = int(sys.argv[6]), float(sys.argv[7])
-#     config.erls_patience = int(sys.argv[8])
-#     config.dataset = sys.argv[9]
-#     config.pretrain_fold_num = sys.argv[10]
-#     config.model = f'efficientnet-phospho-B-15'
-#     config.save_dir = f'/home/hb/python/efficientnet_kincnn/saved_model/{datetime.today().strftime("%m%d")}/DeepPP_{config.dataset}_{datetime.today().strftime("%H%M")}_bs{config.batch_size}_weight{config.pretrain_fold_num}'
-python3 /home/hb/python/efficientnet_kincnn/DeepPhospho4.py 3 2048 500 1e-3 5 7 0.7 50 kincnn4 0
-
-
diff --git a/kincnn.py b/kincnn.py
index eb8e344..fc7b03b 100644
--- a/kincnn.py
+++ b/kincnn.py
@@ -244,7 +244,7 @@ class EfficientNet(nn.Module):
         out_channels = round_filters(3, self._global_params)
         # out_channels = round_filters(1280, self._global_params) <-- 원본
         # out_channels = 1280
-        print(image_size[0]*image_size[1]*out_channels)
+        # print(image_size[0]*image_size[1]*out_channels)
         out_features = image_size[0]*image_size[1]*out_channels
         self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)
         self._bn1 = nn.BatchNorm2d(
@@ -252,10 +252,17 @@ class EfficientNet(nn.Module):
         )
 
         # Final linear layer
-        # self._avg_pooling = nn.AdaptiveAvgPool2d(1)  # <-- 원본
-        out_features = image_size[0] * image_size[1] * out_channels
-        self._dropout = nn.Dropout(self._global_params.dropout_rate)
-        self._fc = nn.Linear(out_features, self._global_params.num_classes)
+        self._avg_pooling = nn.AdaptiveAvgPool2d(1)  # <-- 원본
+        self._avg_pooling = None
+        
+        if self._avg_pooling:
+            out_features = out_channels
+            self._dropout = nn.Dropout(self._global_params.dropout_rate)
+            self._fc = nn.Linear(out_features, self._global_params.num_classes)
+        else:
+            out_features = image_size[0] * image_size[1] * out_channels
+            self._dropout = nn.Dropout(self._global_params.dropout_rate)
+            self._fc = nn.Linear(576, self._global_params.num_classes)
 
         # set activation to memory efficient swish by default
         self._swish = MemoryEfficientSwish()
@@ -363,8 +370,11 @@ class EfficientNet(nn.Module):
         x = self.extract_features(inputs)
 
         # Pooling and final linear layer
-        # x = self._avg_pooling(x)
-        # x = x.view(bs, -1)
+        print(x.shape)
+        if self._avg_pooling:
+            x = self._avg_pooling(x)
+            # print(x.shape)
+            x = x.view(inputs.size(0), -1)
 
         x = x.flatten(start_dim=1)
         x = self._dropout(x)
diff --git a/utils.py b/utils.py
index bbe80a4..b9bedec 100644
--- a/utils.py
+++ b/utils.py
@@ -20,6 +20,64 @@ from torch.utils import model_zoo
 # Help functions for model architecture
 ################################################################################
 
+import math
+from torch.optim.lr_scheduler import _LRScheduler
+
+class CosineAnnealingWarmUpRestarts(_LRScheduler):
+    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):
+        if T_0 <= 0 or not isinstance(T_0, int):
+            raise ValueError("Expected positive integer T_0, but got {}".format(T_0))
+        if T_mult < 1 or not isinstance(T_mult, int):
+            raise ValueError("Expected integer T_mult >= 1, but got {}".format(T_mult))
+        if T_up < 0 or not isinstance(T_up, int):
+            raise ValueError("Expected positive integer T_up, but got {}".format(T_up))
+        self.T_0 = T_0
+        self.T_mult = T_mult
+        self.base_eta_max = eta_max
+        self.eta_max = eta_max
+        self.T_up = T_up
+        self.T_i = T_0
+        self.gamma = gamma
+        self.cycle = 0
+        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)
+        self.T_cur = last_epoch
+    
+    def get_lr(self):
+        if self.T_cur == -1:
+            return self.base_lrs
+        elif self.T_cur < self.T_up:
+            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]
+        else:
+            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2
+                    for base_lr in self.base_lrs]
+
+    def step(self, epoch=None):
+        if epoch is None:
+            epoch = self.last_epoch + 1
+            self.T_cur = self.T_cur + 1
+            if self.T_cur >= self.T_i:
+                self.cycle += 1
+                self.T_cur = self.T_cur - self.T_i
+                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up
+        else:
+            if epoch >= self.T_0:
+                if self.T_mult == 1:
+                    self.T_cur = epoch % self.T_0
+                    self.cycle = epoch // self.T_0
+                else:
+                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))
+                    self.cycle = n
+                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)
+                    self.T_i = self.T_0 * self.T_mult ** (n)
+            else:
+                self.T_i = self.T_0
+                self.T_cur = epoch
+                
+        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)
+        self.last_epoch = math.floor(epoch)
+        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):
+            param_group['lr'] = lr
+
 # GlobalParams and BlockArgs: Two namedtuples
 # Swish and MemoryEfficientSwish: Two implementations of the method
 # round_filters and round_repeats:
@@ -587,11 +645,11 @@ def efficientnet(
 ):
     """Creates a efficientnet model."""
     blocks_args = [
-        "r1_ckh5_ckw1_pkh0_pkw1_csh1_csw1_psh3_psw1_e1_i8_o16_se0.5",
-        "r1_ckh5_ckw1_pkh0_pkw0_csh2_csw1_psh2_psw1_e1_i16_o32_se0.5",
-        "r1_ckh3_ckw1_pkh0_pkw2_csh2_csw1_psh2_psw2_e1_i32_o64_se0.5",
-        'r1_ckh3_ckw1_pkh0_pkw2_csh1_csw1_psh2_psw2_e1_i64_o128_se0.5',
-        # 'r3_k5_s11_e6_i80_o112_se0.25',
+        "r1_ckh5_ckw1_pkh0_pkw1_csh1_csw1_psh3_psw1_e1_i8_o16_se0.25",
+        "r1_ckh5_ckw1_pkh0_pkw0_csh2_csw1_psh2_psw1_e1_i16_o32_se0.25",
+        "r1_ckh3_ckw1_pkh0_pkw2_csh2_csw1_psh2_psw2_e1_i32_o64_se0.25",
+        'r1_ckh3_ckw1_pkh0_pkw2_csh2_csw1_psh2_psw2_e1_i64_o128_se0.25',
+        'r1_ckh3_ckw1_pkh0_pkw2_csh1_csw1_psh1_psw1_e1_i128_o256_se0.25',
         # 'r4_k5_s22_e6_i112_o192_se0.25',
         # 'r1_k3_s11_e6_i192_o320_se0.25',
         # 'r1_k3_s11_e6_i24_o48_se0.25',
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
index 79fca16..8bf61e5 120000
--- a/wandb/debug-internal.log
+++ b/wandb/debug-internal.log
@@ -1 +1 @@
-run-20230518_171924-x8m3pldn/logs/debug-internal.log
\ No newline at end of file
+run-20230523_000609-2uvumsmr/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
index ce491a5..e5f7143 120000
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1 +1 @@
-run-20230518_171924-x8m3pldn/logs/debug.log
\ No newline at end of file
+run-20230523_000609-2uvumsmr/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
index bd2b586..f2676a1 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20230518_171924-x8m3pldn
\ No newline at end of file
+run-20230523_000609-2uvumsmr
\ No newline at end of file
