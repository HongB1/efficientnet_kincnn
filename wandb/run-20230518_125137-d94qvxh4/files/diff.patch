diff --git a/code/C4_evaluation.ipynb b/code/C4_evaluation.ipynb
index a77475b..8a257c9 100644
--- a/code/C4_evaluation.ipynb
+++ b/code/C4_evaluation.ipynb
@@ -14,47 +14,30 @@
     "import kincnn\n",
     "import kincnn2\n",
     "import kincnn3\n",
-    "import kincnn4"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 2,
-   "metadata": {},
-   "outputs": [],
-   "source": [
+    "import kincnn4\n",
     "import sys\n",
-    "# sys.path.append('/home/hb/anaconda3/envs/pp_predict/lib/python3.9/site-packages')\n",
-    "# sys.path.append('/home/hb/python/neoantigen/from_ju/IEDB_data_filtering')\n",
-    "# sys.path.append('/home/hb/python/neoantigen/code/module')\n",
     "sys.path.append('/home/hb/python/phospho/code/module')\n",
     "import pickle\n",
     "import numpy as np\n",
     "import pandas as pd\n",
     "from tqdm.notebook import tqdm\n",
-    "# from benchmark_util import *\n",
     "import torch\n",
-    "from efficientnet_new import *\n",
     "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
     "import sklearn\n",
-    "import seaborn as sns\n",
-    "import matplotlib\n",
     "import matplotlib.pyplot as plt\n",
-    "import numpy as np\n",
-    "import statistics\n",
-    "import itertools"
+    "import numpy as np"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [],
    "source": [
     "import os \n",
     "def load_multiple_model(filedir, datatype):\n",
     "    model_path_list = [f'{filedir}/{file}' for file in os.listdir(filedir) if \"best\" in file]\n",
-    "    print(model_path_list)\n",
+    "    # print(model_path_list)\n",
     "    globals()['model_list_' + datatype] = []\n",
     "    # estimators = []\n",
     "    for i in range(len(model_path_list)):\n",
@@ -110,125 +93,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 21,
    "metadata": {},
    "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "['/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn1_1846_bs1024_weight0/3fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn1_1846_bs1024_weight0/0fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn1_1846_bs1024_weight0/1fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn1_1846_bs1024_weight0/4fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn1_1846_bs1024_weight0/2fold_best_model.pth']\n"
-     ]
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "f7cc79c6a30f4ee085d0509620ebb4a9",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "59f067efeadb49fc82e1f4a2b1f0ec05",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "bedb1e2274194115af9f7c1c96fd5b90",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "b39fcc92e8cf4851bb0296e613da4824",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "0cd280b00a5d426e9bc916b73a3d74e7",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "['/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn2_1846_bs1024_weight0/3fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn2_1846_bs1024_weight0/0fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn2_1846_bs1024_weight0/1fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn2_1846_bs1024_weight0/4fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn2_1846_bs1024_weight0/2fold_best_model.pth']\n"
-     ]
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "b4e687cc33784bcc9ab46cda7b741c83",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "3dce7de670f946e7b63f2feccd87613f",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "0368726f5c084bd5895ca6e11e846d80",
+       "model_id": "54c8e806d3334fd28684b55ac2401e6b",
        "version_major": 2,
        "version_minor": 0
       },
@@ -242,7 +113,7 @@
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "cb04243536e74bf68c168ac100ade935",
+       "model_id": "26e09a01043f430ca980e23e763d1bcb",
        "version_major": 2,
        "version_minor": 0
       },
@@ -256,7 +127,7 @@
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "cd224d97830846adbcda6f9a17df2065",
+       "model_id": "8435ae6bdc0145d7a02b66dbe50ef6d0",
        "version_major": 2,
        "version_minor": 0
       },
@@ -267,17 +138,10 @@
      "metadata": {},
      "output_type": "display_data"
     },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "['/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn3_1846_bs1024_weight0/3fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn3_1846_bs1024_weight0/0fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn3_1846_bs1024_weight0/1fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn3_1846_bs1024_weight0/4fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn3_1846_bs1024_weight0/2fold_best_model.pth']\n"
-     ]
-    },
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "b9206f8fde2241f094c50d52a0ef9d39",
+       "model_id": "36c8fd0195e0406d824c606e1f894404",
        "version_major": 2,
        "version_minor": 0
       },
@@ -291,126 +155,7 @@
     {
      "data": {
       "application/vnd.jupyter.widget-view+json": {
-       "model_id": "ba3ca9a02e524621b4e4ca6347b2e777",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "975bbcd85d954ddd95daa92c61e829a1",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "b4c6f7b5e5e34878a303e706c4e2be7f",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "c5aa1a9a73f44a02adb8907b70ff9611",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "['/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn4_1846_bs1024_weight0/3fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn4_1846_bs1024_weight0/0fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn4_1846_bs1024_weight0/1fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn4_1846_bs1024_weight0/4fold_best_model.pth', '/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn4_1846_bs1024_weight0/2fold_best_model.pth']\n"
-     ]
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "619811cb4a044401b059780d4f7c7010",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "9dad365bdd5e41d897a69d1d22cf2495",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "a59394447917403585cef6f49a38121a",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "7d4088bf23a44dd89ab42658900f18d1",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "6b871f4d70854ccf807793b179c3229b",
+       "model_id": "2fffad21111f44bd8d4c6ef43aecad67",
        "version_major": 2,
        "version_minor": 0
       },
@@ -425,10 +170,11 @@
    "source": [
     "import re\n",
     "df_test = pd.read_pickle(\"/home/hb/python/phospho/data/required/0308_final_train_test/test1.pkl\")\n",
-    "time = 1846\n",
-    "save_dir = '/home/hb/python/efficientnet_kincnn/saved_model/0517'\n",
+    "time = 1100\n",
+    "save_dir = '/home/hb/python/efficientnet_kincnn/saved_model/0518'\n",
     "\n",
-    "filedir_list = [f'{save_dir}/DeepPP_kincnn{x}_{time}_bs1024_weight0' for x in range(1, 5)]\n",
+    "# filedir_list = [f'{save_dir}/DeepPP_kincnn{x}_{time}_bs1024_weight0' for x in range(1, 5)]\n",
+    "filedir_list = [f'{save_dir}/DeepPP_kincnn{1}_{1100}_bs1024_weight0']\n",
     "model_list = []\n",
     "auc_list = []\n",
     "for filedir in filedir_list:\n",
@@ -441,47 +187,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 95,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "'0517/DeepPP_kincnn1_1846_bs1024_weight0'"
-      ]
-     },
-     "execution_count": 95,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "'/'.join(filedir_list[0].split('/')[-2:])"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 78,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "4"
-      ]
-     },
-     "execution_count": 78,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "len(model_list)"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 98,
+   "execution_count": 19,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -489,8 +195,8 @@
     "\n",
     "warnings.filterwarnings(action='ignore') \n",
     "\n",
-    "df = pd.read_csv('/home/hb/python/efficientnet_kincnn/model_info.csv', index_col=False)\n",
-    "del df['Unnamed: 0']\n",
+    "df = pd.read_excel('/home/hb/python/efficientnet_kincnn/model_info.xlsx', engine='openpyxl')\n",
+    "\n",
     "\n",
     "for model, auc, model_path in zip(model_list, auc_list, filedir_list):\n",
     "    _model = model[0]\n",
@@ -511,224 +217,7 @@
     "    model_params_dict['AUC'] = auc\n",
     "    model_params_dict['model_path'] = '/'.join(model_path.split('/')[-2:])\n",
     "    df = df.append(model_params_dict, ignore_index=True)\n",
-    "df.to_csv(\"/home/hb/python/efficientnet_kincnn/model_info.csv\")"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 71,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>conv_stem_kernel_size</th>\n",
-       "      <th>conv_stem_stride_size</th>\n",
-       "      <th>conv_stem_pooling</th>\n",
-       "      <th>conv_stem_pooling_kernel_size</th>\n",
-       "      <th>MBconv0_inp</th>\n",
-       "      <th>MBconv0_oup</th>\n",
-       "      <th>MBconv0_kernel_size</th>\n",
-       "      <th>MBconv0_stride</th>\n",
-       "      <th>last_features</th>\n",
-       "      <th>AUC</th>\n",
-       "      <th>model_path</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>0</th>\n",
-       "      <td>(3, 1)</td>\n",
-       "      <td>(1, 1)</td>\n",
-       "      <td>True</td>\n",
-       "      <td>(2, 1)</td>\n",
-       "      <td>8</td>\n",
-       "      <td>16</td>\n",
-       "      <td>(5, 1)</td>\n",
-       "      <td>(2, 1)</td>\n",
-       "      <td>7920</td>\n",
-       "      <td>0.8262</td>\n",
-       "      <td>DeepPP_kincnn4_1846_bs1024_weight0</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>1</th>\n",
-       "      <td>(3, 1)</td>\n",
-       "      <td>(1, 1)</td>\n",
-       "      <td>True</td>\n",
-       "      <td>(2, 1)</td>\n",
-       "      <td>8</td>\n",
-       "      <td>16</td>\n",
-       "      <td>(5, 1)</td>\n",
-       "      <td>(2, 1)</td>\n",
-       "      <td>7920</td>\n",
-       "      <td>0.8262</td>\n",
-       "      <td>DeepPP_kincnn4_1846_bs1024_weight0</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "  conv_stem_kernel_size conv_stem_stride_size  conv_stem_pooling  \\\n",
-       "0                (3, 1)                (1, 1)               True   \n",
-       "1                (3, 1)                (1, 1)               True   \n",
-       "\n",
-       "  conv_stem_pooling_kernel_size  MBconv0_inp  MBconv0_oup MBconv0_kernel_size  \\\n",
-       "0                        (2, 1)            8           16              (5, 1)   \n",
-       "1                        (2, 1)            8           16              (5, 1)   \n",
-       "\n",
-       "  MBconv0_stride  last_features     AUC                          model_path  \n",
-       "0         (2, 1)           7920  0.8262  DeepPP_kincnn4_1846_bs1024_weight0  \n",
-       "1         (2, 1)           7920  0.8262  DeepPP_kincnn4_1846_bs1024_weight0  "
-      ]
-     },
-     "execution_count": 71,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "df"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 55,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "{'conv_stem_kernel_size': (3, 1),\n",
-       " 'conv_stem_stride_size': (1, 1),\n",
-       " 'conv_stem_pooling': True,\n",
-       " 'conv_stem_pooling_kernel_size': (2, 1),\n",
-       " 'MBconv0_inp': 8,\n",
-       " 'MBconv0_oup': 16,\n",
-       " 'MBconv0_kernel_size': (5, 1),\n",
-       " 'MBconv0_stride': (2, 1),\n",
-       " 'last_features': 7920,\n",
-       " 'AUC': 0.8262,\n",
-       " 'model_path': 'DeepPP_kincnn4_1846_bs1024_weight0'}"
-      ]
-     },
-     "execution_count": 55,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "model_params_dict"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 9,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "459d3736b1ca45d29ee819293567bf1b",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "11ec3cd897f94f3ebcfbb35ac2495e34",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "c703b9b5da684bb195bd0c810f513d22",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "2415a8fbc0034f0c9532355515223a93",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "application/vnd.jupyter.widget-view+json": {
-       "model_id": "b2f6988b8ed44417a686f9e1b9eac159",
-       "version_major": 2,
-       "version_minor": 0
-      },
-      "text/plain": [
-       "  0%|          | 0/4 [00:00<?, ?it/s]"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "0.8061613750000001"
-      ]
-     },
-     "execution_count": 9,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "df_test = pd.read_pickle(\"/home/hb/python/phospho/data/required/0308_final_train_test/test1.pkl\")\n",
-    "auc = ensemble(model_list_transfer, df_test)\n",
-    "auc"
+    "df.to_excel(\"/home/hb/python/efficientnet_kincnn/model_info.xlsx\", index=False)"
    ]
   },
   {
diff --git a/code/phospho_preprocessing.py b/code/phospho_preprocessing.py
index 9a9621b..9cee016 100644
--- a/code/phospho_preprocessing.py
+++ b/code/phospho_preprocessing.py
@@ -16,22 +16,22 @@ import pickle
 
 def prepare_dataset(dataset_mode):
     
-    # if dataset_mode == 'transfer_learning_1':
+    if dataset_mode == 'kincnn1':
         
-    df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train1.pkl")
-    print(df.iloc[-1:])
-    # elif dataset_mode == 'transfer_learning_2':
+        df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train1.pkl")
+        print(df.iloc[-1:])
+    elif dataset_mode == 'kincnn2':
         
-    #     df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train2.pkl")
-    #     print(df.iloc[-1:])
-    # elif dataset_mode == 'transfer_learning_3':
+        df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train2.pkl")
+        print(df.iloc[-1:])
+    elif dataset_mode == 'kincnn3':
         
-    #     df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train3.pkl")
-    #     print(df.iloc[-1:])
-    # elif dataset_mode == 'transfer_learning_4':
+        df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train3.pkl")
+        print(df.iloc[-1:])
+    elif dataset_mode == 'kincnn4':
         
-    #     df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train4.pkl")
-    #     print(df.iloc[-1:])
+        df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train4.pkl")
+        print(df.iloc[-1:])
     # elif dataset_mode == 'transfer_learning_5':
         
     #     df = pd.read_pickle("/home/hb/python/phospho/data/required/0308_final_train_test/train5.pkl")
diff --git a/gpu_1.sh b/gpu_1.sh
index e665121..17d2aab 100755
--- a/gpu_1.sh
+++ b/gpu_1.sh
@@ -25,6 +25,6 @@
 #     config.pretrain_fold_num = sys.argv[10]
 #     config.model = f'efficientnet-phospho-B-15'
 #     config.save_dir = f'/home/hb/python/efficientnet_kincnn/saved_model/{datetime.today().strftime("%m%d")}/DeepPP_{config.dataset}_{datetime.today().strftime("%H%M")}_bs{config.batch_size}_weight{config.pretrain_fold_num}'
-python3 /home/hb/python/efficientnet_kincnn/DeepPhospho2.py 1 1024 500 1e-3 5 7 0.7 50 kincnn2 0
+python3 /home/hb/python/efficientnet_kincnn/DeepPhospho2.py 2 512 500 1e-3 5 7 0.7 50 kincnn2 0
 
 
diff --git a/kincnn.py b/kincnn.py
index d07913a..eb8e344 100644
--- a/kincnn.py
+++ b/kincnn.py
@@ -119,7 +119,6 @@ class MBConvBlock(nn.Module):
             x = self._swish(x)
 
         x = self._depthwise_conv(x)  # 2
-        # x = partial()
         x = self._bn1(x)
         if self._block_args.pool_kernel_size:
             x = self._depthwise_max_pooling(x)
@@ -233,7 +232,7 @@ class EfficientNet(nn.Module):
             image_size = calculate_output_image_size(image_size, block_args.conv_stride)
             if block_args.num_repeat > 1:  # modify block_args to keep same output size
                 block_args = block_args._replace(
-                    input_filters=block_args.output_filters, stride=1
+                    input_filters=block_args.output_filters, conv_stride=(1, 1)
                 )
             for _ in range(block_args.num_repeat - 1):
                 self._blocks.append(
@@ -254,6 +253,7 @@ class EfficientNet(nn.Module):
 
         # Final linear layer
         # self._avg_pooling = nn.AdaptiveAvgPool2d(1)  # <-- 원본
+        out_features = image_size[0] * image_size[1] * out_channels
         self._dropout = nn.Dropout(self._global_params.dropout_rate)
         self._fc = nn.Linear(out_features, self._global_params.num_classes)
 
diff --git a/kincnn2.py b/kincnn2.py
index 9afb8a1..3796947 100644
--- a/kincnn2.py
+++ b/kincnn2.py
@@ -232,7 +232,7 @@ class EfficientNet(nn.Module):
             image_size = calculate_output_image_size(image_size, block_args.conv_stride)
             if block_args.num_repeat > 1:  # modify block_args to keep same output size
                 block_args = block_args._replace(
-                    input_filters=block_args.output_filters, stride=1
+                    input_filters=block_args.output_filters, conv_stride=(1, 1)
                 )
             for _ in range(block_args.num_repeat - 1):
                 self._blocks.append(
diff --git a/test.ipynb b/test.ipynb
index 41c18b9..49d2b72 100644
--- a/test.ipynb
+++ b/test.ipynb
@@ -2,6 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
+<<<<<<< HEAD
    "execution_count": 3,
    "metadata": {},
    "outputs": [],
@@ -178,12 +179,12 @@
   },
   {
    "cell_type": "code",
+=======
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
    "execution_count": 1,
-   "metadata": {
-    "collapsed": true
-   },
    "outputs": [],
    "source": [
+<<<<<<< HEAD
     "import re\n",
     "import collections\n",
     "import torch\n",
@@ -268,15 +269,22 @@
     "\n",
     "    return blocks_args, global_params\n",
     "\n",
+=======
+    "from utils import efficientnet\n",
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
     "blocks_args, global_params = efficientnet(width_coefficient=1.0, depth_coefficient=1.0, dropout_rate=0.7, image_size=[263, 15])"
    ]
   },
   {
    "cell_type": "code",
+<<<<<<< HEAD
    "execution_count": 227,
    "metadata": {
     "collapsed": false
    },
+=======
+   "execution_count": 2,
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
    "outputs": [
     {
      "name": "stdout",
@@ -284,11 +292,7 @@
      "text": [
       "GlobalParams(width_coefficient=1.0, depth_coefficient=1.0, image_size=[263, 15], dropout_rate=0.7, num_classes=1, batch_norm_momentum=0.99, batch_norm_epsilon=0.001, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, include_top=None)\n",
       "\n",
-      "MBConvblock 0:  BlockArgs(num_repeat=1, kernel_size=(8, 2), stride=(2, 2), expand_ratio=2, input_filters=8, output_filters=16, se_ratio=0.25, id_skip=True)\n",
-      "\n",
-      "MBConvblock 1:  BlockArgs(num_repeat=1, kernel_size=(8, 3), stride=(2, 1), expand_ratio=2, input_filters=16, output_filters=32, se_ratio=0.25, id_skip=True)\n",
-      "\n",
-      "MBConvblock 2:  BlockArgs(num_repeat=1, kernel_size=(6, 3), stride=(2, 2), expand_ratio=2, input_filters=32, output_filters=64, se_ratio=0.25, id_skip=True)\n",
+      "MBConvblock 0:  BlockArgs(num_repeat=1, conv_kernel_size=(5, 1), pool_kernel_size=(3, 1), conv_stride=(1, 1), pool_stride=(3, 1), expand_ratio=1, input_filters=2, output_filters=4, se_ratio=0.25, id_skip=True)\n",
       "\n"
      ]
     }
@@ -303,6 +307,7 @@
   },
   {
    "cell_type": "code",
+<<<<<<< HEAD
    "execution_count": 228,
    "metadata": {
     "collapsed": false
@@ -336,11 +341,27 @@
    "metadata": {
     "collapsed": false
    },
+=======
+   "execution_count": null,
+   "outputs": [],
+   "source": [],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 12,
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
    "outputs": [],
    "source": [
+    "from utils import Conv2dStaticSamePadding, MaxPool2dStaticSamePadding\n",
+    "from functools import partial\n",
+    "\n",
     "bn_mom = 1 - global_params.batch_norm_momentum\n",
     "bn_eps = global_params.batch_norm_epsilon\n",
     "image_size = global_params.image_size\n",
+<<<<<<< HEAD
     "Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)"
    ]
   },
@@ -356,19 +377,39 @@
       "text/plain": [
        "[132, 15]"
       ]
+=======
+    "Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)\n",
+    "MaxPool2d = partial(MaxPool2dStaticSamePadding_, image_size=image_size)"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 13,
+   "outputs": [
+    {
+     "data": {
+      "text/plain": "[263, 15]"
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
      },
-     "execution_count": 237,
+     "execution_count": 13,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
+    "from torch import nn\n",
+    "from utils import round_filters, calculate_output_image_size, MemoryEfficientSwish\n",
+    "\n",
     "# Stem\n",
     "image_size = [263, 15]\n",
     "in_channels = 1\n",
     "out_channels = round_filters(8, global_params)\n",
-    "_conv_stem = Conv2d(in_channels, out_channels, kernel_size=(15, 1), stride=(2, 1), bias=False, image_size=image_size)\n",
+    "_conv_stem = Conv2d(in_channels, out_channels, kernel_size=(5, 1), stride=(1, 1), bias=False, image_size=image_size)\n",
     "_bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
+<<<<<<< HEAD
     "image_size = calculate_output_image_size_(image_size, stride=(2, 1))\n",
     "image_size"
    ]
@@ -965,11 +1006,17 @@
     }
    ],
    "source": [
+=======
+    "_max_pool = MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n",
+    "_swish = MemoryEfficientSwish()\n",
+    "image_size = calculate_output_image_size(image_size, stride=(1, 1))\n",
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
     "image_size"
    ]
   },
   {
    "cell_type": "code",
+<<<<<<< HEAD
    "execution_count": 119,
    "metadata": {
     "collapsed": false
@@ -1012,13 +1059,45 @@
       "text/plain": [
        "torch.Size([1, 8, 132, 15])"
       ]
+=======
+   "execution_count": 1,
+   "outputs": [],
+   "source": [
+    "import kincnn\n",
+    "import torch"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "outputs": [],
+   "source": [
+    "x = torch.randn(1, 1, 263, 15)\n",
+    "model = kincnn.EfficientNet.from_name('efficientnet-phospho-B-15')"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "outputs": [
+    {
+     "data": {
+      "text/plain": "tensor([[0.6308]], grad_fn=<SigmoidBackward0>)"
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
      },
-     "execution_count": 121,
+     "execution_count": 3,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
+<<<<<<< HEAD
     "# Stem\n",
     "x0 = torch.randn((1, 1, 263, 15))\n",
     "x1 = _conv_stem(x0)\n",
@@ -1044,22 +1123,80 @@
    "metadata": {
     "collapsed": false
    },
+=======
+    "model(x)"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 7,
+   "outputs": [],
+   "source": [
+    "import pytorch_model_summary"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 8,
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "3\n",
-      "torch.Size([1, 8, 132, 15])\n",
-      "torch.Size([1, 16, 66, 8])\n",
-      "torch.Size([1, 16, 66, 8])\n",
-      "torch.Size([1, 32, 33, 8])\n",
-      "torch.Size([1, 32, 33, 8])\n",
-      "torch.Size([1, 64, 17, 4])\n"
+      "-------------------------------------------------------------------------------------\n",
+      "                    Layer (type)         Input Shape         Param #     Tr. Param #\n",
+      "=====================================================================================\n",
+      "                     ZeroPad2d-1     [1, 1, 263, 15]               0               0\n",
+      "                   BatchNorm2d-2     [1, 8, 263, 15]              16              16\n",
+      "                     ZeroPad2d-3     [1, 8, 263, 15]               0               0\n",
+      "          MemoryEfficientSwish-4     [1, 8, 132, 15]               0               0\n",
+      "       Conv2dStaticSamePadding-5     [1, 8, 132, 15]              40              40\n",
+      "                   BatchNorm2d-6     [1, 8, 132, 15]              16              16\n",
+      "    MaxPool2dStaticSamePadding-7     [1, 8, 132, 15]               0               0\n",
+      "          MemoryEfficientSwish-8      [1, 8, 44, 15]               0               0\n",
+      "       Conv2dStaticSamePadding-9        [1, 8, 1, 1]              18              18\n",
+      "      Conv2dStaticSamePadding-10        [1, 2, 1, 1]              24              24\n",
+      "      Conv2dStaticSamePadding-11      [1, 8, 44, 15]              64              64\n",
+      "                  BatchNorm2d-12      [1, 8, 44, 15]              16              16\n",
+      "      Conv2dStaticSamePadding-13      [1, 8, 44, 15]              24              24\n",
+      "                  BatchNorm2d-14      [1, 8, 44, 15]              16              16\n",
+      "   MaxPool2dStaticSamePadding-15      [1, 8, 44, 15]               0               0\n",
+      "         MemoryEfficientSwish-16      [1, 8, 22, 15]               0               0\n",
+      "      Conv2dStaticSamePadding-17        [1, 8, 1, 1]              18              18\n",
+      "      Conv2dStaticSamePadding-18        [1, 2, 1, 1]              24              24\n",
+      "      Conv2dStaticSamePadding-19      [1, 8, 22, 15]             128             128\n",
+      "                  BatchNorm2d-20     [1, 16, 22, 15]              32              32\n",
+      "      Conv2dStaticSamePadding-21     [1, 16, 22, 15]             144             144\n",
+      "                  BatchNorm2d-22     [1, 16, 22, 15]              32              32\n",
+      "   MaxPool2dStaticSamePadding-23     [1, 16, 22, 15]               0               0\n",
+      "         MemoryEfficientSwish-24      [1, 16, 11, 8]               0               0\n",
+      "      Conv2dStaticSamePadding-25       [1, 16, 1, 1]              68              68\n",
+      "      Conv2dStaticSamePadding-26        [1, 4, 1, 1]              80              80\n",
+      "      Conv2dStaticSamePadding-27      [1, 16, 11, 8]             512             512\n",
+      "                  BatchNorm2d-28      [1, 32, 11, 8]              64              64\n",
+      "                     Identity-29      [1, 32, 11, 8]               0               0\n",
+      "                  BatchNorm2d-30       [1, 8, 11, 8]              16              16\n",
+      "            AdaptiveAvgPool2d-31       [1, 8, 11, 8]               0               0\n",
+      "                      Dropout-32              [1, 8]               0               0\n",
+      "                       Linear-33              [1, 8]               9               9\n",
+      "=====================================================================================\n",
+      "Total params: 1,361\n",
+      "Trainable params: 1,361\n",
+      "Non-trainable params: 0\n",
+      "Batch size: 1\n",
+      "-------------------------------------------------------------------------------------\n"
      ]
     }
    ],
    "source": [
+<<<<<<< HEAD
     "print(len(blocks))\n",
     "\n",
     "for idx, block in enumerate(blocks):\n",
@@ -1144,13 +1281,75 @@
       "text/plain": [
        "torch.Size([1, 128, 17, 4])"
       ]
+=======
+    "print(pytorch_model_summary.summary(model, torch.zeros(1, 1, 263, 15), show_input=True, show_hierarchical=False, max_depth=2, batch_size=1))"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 15,
+   "outputs": [
+    {
+     "ename": "RuntimeError",
+     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 1, 1, 267, 15]",
+     "output_type": "error",
+     "traceback": [
+      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
+      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
+      "Cell \u001B[0;32mIn[15], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchsummary\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary\n\u001B[0;32m----> 2\u001B[0m \u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m263\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
+      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torchsummary/torchsummary.py:72\u001B[0m, in \u001B[0;36msummary\u001B[0;34m(model, input_size, batch_size, device)\u001B[0m\n\u001B[1;32m     68\u001B[0m model\u001B[38;5;241m.\u001B[39mapply(register_hook)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# make a forward pass\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# print(x.shape)\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# remove these hooks\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m h \u001B[38;5;129;01min\u001B[39;00m hooks:\n",
+      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
+      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1509\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1510\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
+      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/kincnn.py:344\u001B[0m, in \u001B[0;36mEfficientNet.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls extract_features to extract features, applies final linear layer, and returns logits.\"\"\"\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;66;03m# bs = inputs.size(0)\u001B[39;00m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;66;03m# print(bs)\u001B[39;00m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;66;03m# Convolution layers\u001B[39;00m\n\u001B[0;32m--> 344\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# Pooling and final linear layer\u001B[39;00m\n\u001B[1;32m    347\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_avg_pooling(x)\n",
+      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/kincnn.py:320\u001B[0m, in \u001B[0;36mEfficientNet.extract_features\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns output of the final convolution layer\"\"\"\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;66;03m# Stem\u001B[39;00m\n\u001B[0;32m--> 320\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_stem\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bn0(x)\n\u001B[1;32m    322\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_pooling(x)\n",
+      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
+      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1548\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1545\u001B[0m     bw_hook \u001B[38;5;241m=\u001B[39m hooks\u001B[38;5;241m.\u001B[39mBackwardHook(\u001B[38;5;28mself\u001B[39m, full_backward_hooks, backward_pre_hooks)\n\u001B[1;32m   1546\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[0;32m-> 1548\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1549\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n\u001B[1;32m   1550\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook_id, hook \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[1;32m   1551\u001B[0m         \u001B[38;5;241m*\u001B[39m_global_forward_hooks\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[1;32m   1552\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[1;32m   1553\u001B[0m     ):\n",
+      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/utils.py:338\u001B[0m, in \u001B[0;36mConv2dStaticSamePadding.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    336\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    337\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatic_padding(x)\n\u001B[0;32m--> 338\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
+      "\u001B[0;31mRuntimeError\u001B[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 1, 1, 267, 15]"
+     ]
+    }
+   ],
+   "source": [
+    "from torchsummary import summary\n",
+    "summary(model, input_size=(1, 1, 263, 15))"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 20,
+   "outputs": [],
+   "source": [
+    "from utils import round_filters\n",
+    "out_channels = round_filters(\n",
+    "            2, global_params\n",
+    "        )  # number of output channels"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 21,
+   "outputs": [
+    {
+     "data": {
+      "text/plain": "GlobalParams(width_coefficient=1.0, depth_coefficient=1.0, image_size=[263, 15], dropout_rate=0.7, num_classes=1, batch_norm_momentum=0.99, batch_norm_epsilon=0.001, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, include_top=None)"
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
      },
-     "execution_count": 273,
+     "execution_count": 21,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
+<<<<<<< HEAD
     "x = _conv_head(x)\n",
     "x = _bn1(x)\n",
     "x = _swish(x)\n",
@@ -1180,8 +1379,23 @@
       "text/plain": [
        "128"
       ]
+=======
+    "global_params"
+   ],
+   "metadata": {
+    "collapsed": false
+   }
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 22,
+   "outputs": [
+    {
+     "data": {
+      "text/plain": "8"
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
      },
-     "execution_count": 295,
+     "execution_count": 22,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -1192,6 +1406,7 @@
   },
   {
    "cell_type": "code",
+<<<<<<< HEAD
    "execution_count": 292,
    "metadata": {
     "collapsed": false
@@ -1643,6 +1858,8 @@
   },
   {
    "cell_type": "code",
+=======
+>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
    "execution_count": null,
    "metadata": {},
    "outputs": [],
diff --git a/train.py b/train.py
new file mode 100644
index 0000000..4a684f8
--- /dev/null
+++ b/train.py
@@ -0,0 +1,340 @@
+import sys
+
+# sys.path.append('/home/hb/anaconda3/envs/pp_predict/lib/python3.9/site-packages')
+# # sys.path.append('/home/hb/python/neoantigen/from_ju/IEDB_data_filtering')
+# # # sys.path.append('/home/hb/python/neoantigen/code/module')
+sys.path.append("/home/hb/python/phospho/code/module")
+import os
+import random
+from datetime import datetime
+
+import numpy as np
+import torch
+import torch.utils.data as data_utils
+import wandb
+from EarlyStopping import EarlyStopping
+from matplotlib import pyplot as plt
+from module.efficientnet_new import EfficientNet
+from phospho_preprocessing import AttrDict, prepare_dataset
+from precision_recall import precision_recall
+from Radam import RAdam
+from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
+from sklearn.model_selection import KFold, StratifiedShuffleSplit
+from torch import nn
+from torch.autograd import Variable
+from torch.utils.data import ConcatDataset, DataLoader, Dataset
+from tqdm.auto import tqdm
+
+if __name__ == "__main__":
+    config = AttrDict()
+    config.gpu_num = sys.argv[1]
+    config.batch_size = int(sys.argv[2])
+    config.n_epoch = int(sys.argv[3])
+    config.defalut_learning_rate = float(sys.argv[4])
+    config.fold_num = int(sys.argv[5])
+    config.scheduler_patience, config.scheduler_factor = int(sys.argv[6]), float(
+        sys.argv[7]
+    )
+    config.erls_patience = int(sys.argv[8])
+    config.dataset = sys.argv[9]
+    config.pretrain_fold_num = sys.argv[10]
+    config.model = f"efficientnet-phospho-B-15"
+    config.save_dir = f'/home/hb/python/phospho/saved_model/{datetime.today().strftime("%m%d")}/DeepPP_{config.dataset}_{datetime.today().strftime("%H%M")}_bs{config.batch_size}_weight{config.pretrain_fold_num}'
+
+    os.makedirs(f"{config.save_dir}", exist_ok=True)
+
+    import yaml
+
+    with open(f"{config.save_dir}/config.yaml", "w") as f:
+        yaml.dump(config, f)
+
+
+def seed_everything(seed: int = 42):
+    random.seed(seed)
+    np.random.seed(seed)
+    os.environ["PYTHONHASHSEED"] = str(seed)
+    torch.manual_seed(seed)
+    torch.cuda.manual_seed(seed)  # type: ignore
+    torch.backends.cudnn.deterministic = True  # type: ignore
+    torch.backends.cudnn.benchmark = False  # type: ignore
+
+
+seed_everything(42)
+os.environ["CUDA_VISIBLE_DEVICES"] = config.gpu_num  # Set the GPU number to use
+device = torch.device(f"cuda:{config.gpu_num}" if torch.cuda.is_available() else "cpu")
+
+print("Device:", device)
+print("Current cuda device:", torch.cuda.current_device())
+print(f"Using CUDA_VISIBLE_DEVICES {config.gpu_num}")
+print("Count of using GPUs:", torch.cuda.device_count())
+
+"""prepare dataset"""
+dtset = prepare_dataset(dataset_mode=config.dataset)
+train_set = dtset[0]
+valid_set = dtset[1]
+print(train_set, valid_set)
+train_loader = data_utils.DataLoader(
+    train_set, batch_size=config.batch_size, pin_memory=True, shuffle=True
+)
+valid_loader = data_utils.DataLoader(
+    valid_set,
+    batch_size=config.batch_size,
+)
+
+dataloaders = {"train": train_loader, "valid": valid_loader}
+dataset_sizes = {x: len(dataloaders[x]) for x in ["train", "valid"]}
+dataset = ConcatDataset([train_set, valid_set])
+
+
+def train_model_5cv():
+    # dataset = data_utils.DataLoader(, batch_size=config.batch_size, pin_memory=True, shuffle=True)
+    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
+    kfold = KFold(n_splits=5, shuffle=True)
+
+    wandb.init(project="phospho", entity="jeguring", reinit=True, config=config)
+    print(config)
+    project_name = f'bs{config.batch_size}_{datetime.today().strftime("%m%d%H%M")}'
+    wandb.run.name = project_name
+
+    for fold, (train_idx, valid_idx) in enumerate(kfold.split(dataset)):
+        globals()[f"{fold}_train_loss"] = []
+        globals()[f"{fold}_train_precision"] = []
+        globals()[f"{fold}_train_recall"] = []
+        globals()[f"{fold}_train_f1"] = []
+        globals()[f"{fold}_train_acc"] = []
+
+        globals()[f"{fold}_valid_loss"] = []
+        globals()[f"{fold}_valid_precision"] = []
+        globals()[f"{fold}_valid_recall"] = []
+        globals()[f"{fold}_valid_f1"] = []
+        globals()[f"{fold}_valid_acc"] = []
+        globals()[f"{fold}_lr"] = []
+
+        globals()[f"{fold}_result"] = []
+        print(f"FOLD {fold}")
+        print("--------------------------------")
+
+        """model compile"""
+        model = EfficientNet.from_name(f"{config.model}")
+
+        """optimizer & loss"""
+
+        optimizer = RAdam(model.parameters(), lr=config.defalut_learning_rate)
+        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
+            optimizer,
+            mode="min",
+            factor=config.scheduler_factor,
+            patience=config.scheduler_patience,
+            threshold=0.0001,
+            cooldown=0,
+            min_lr=0,
+            verbose=1,
+        )
+        criterion = nn.BCELoss()
+        # criterion = nn.CrossEntropyLoss()
+        print("lr: ", optimizer.param_groups[0]["lr"])
+        state_dict = torch.load(
+            f"/home/hb/python/phospho/saved_model/0224/DeepPP_pretrain_1090_1708_bs1024_weight0/{config.pretrain_fold_num}fold_best_model.pth"
+        )
+        model.load_state_dict(state_dict["state_dict"])
+        model = model.to(device)
+        criterion.to(device)
+
+        best_model_weights = model.state_dict()
+        best_loss = 1000000.0
+
+        # Define data loaders for training and testing data in this fold
+        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)
+        test_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)
+
+        # Define data loaders for training and testing data in this fold
+        trainloader = torch.utils.data.DataLoader(
+            dataset, batch_size=config.batch_size, sampler=train_subsampler
+        )
+        validloader = torch.utils.data.DataLoader(
+            dataset, batch_size=config.batch_size, sampler=test_subsampler
+        )
+
+        early_stopping = EarlyStopping(patience=config.erls_patience, verbose=True)
+
+        for epoch in tqdm(range(config.n_epoch), position=0, leave=True):
+            print("-" * 60)
+            print("Epoch {}/{}".format(epoch + 1, config.n_epoch))
+
+            train_corrects = 0.0
+            train_loss = 0.0
+            train_precision, train_recall, train_f1 = 0.0, 0.0, 0.0
+            # rus = RandomUnderSampler(random_state=epoch)
+            # undersampling_idx, _ = rus.fit_resample(train_idx, y_train)
+            # undersampling_idx = undersampling_idx.flatten()
+
+            # X_urs = X_train[undersampling_idx]
+            # y_urs = y_train[undersampling_idx]
+            # print(y_urs.bincount())
+            # train_dataset = data_utils.TensorDataset(torch.tensor(X_urs), torch.tensor(y_urs))
+
+            # trainloader = torch.utils.data.DataLoader(
+            #                 train_dataset,
+            #                 batch_size=config.batch_size,)
+            # validloader = torch.utils.data.DataLoader(
+            #                 valid_dataset,
+            #                 batch_size=config.batch_size,)
+            for _, (inputs, labels) in enumerate(
+                tqdm(trainloader, position=1, leave=True)
+            ):
+                model.train(True)
+                # inputs, labels = data
+                inputs = Variable(
+                    inputs.to(device, dtype=torch.float), requires_grad=True
+                )
+                # print(labels.shape)
+                # print(labels)
+                # labels = labels.unsqueeze(1).to(device, dtype=torch.float)
+                # print(labels)
+                # print(labels.shape)
+                labels = Variable(labels.to(device))
+                # print(labels)
+
+                pred = model(inputs)  # forward
+                precision, recall, f1 = precision_recall(
+                    labels.float().view(-1, 1), pred
+                )  # outputs = net(inputs)
+                # loss = criterion(pred, labels)
+                loss = criterion(pred, labels.float().view(-1, 1)).to(device)
+                preds = (pred > 0.5).float()
+
+                """backward"""
+                optimizer.zero_grad()  # zero the parameter gradients
+                loss.backward()
+                optimizer.step()
+
+                """train record"""
+                train_loss += loss.item()
+                train_preds = (pred >= 0.5).float()
+                train_corrects += accuracy_score(labels.cpu(), train_preds.cpu())
+                train_precision += precision.detach()
+                train_recall += recall.detach()
+                train_f1 += f1.detach()
+
+            """epoch train record"""
+            epoch_train_loss = train_loss / len(trainloader)
+            epoch_train_precision = train_precision / len(trainloader)
+            epoch_train_recall = train_recall / len(trainloader)
+            epoch_train_f1 = train_f1 / len(trainloader)
+            epoch_train_acc = train_corrects / len(trainloader)
+            # # ---train 1 epoch 끝---
+
+            # ---valid 1 epoch
+            with torch.no_grad():
+                model.eval()
+
+                valid_corrects = 0.0
+                valid_loss = 0.0
+                valid_precision, valid_recall, valid_f1 = 0.0, 0.0, 0.0
+
+                for i, (inputs, labels) in enumerate(
+                    tqdm(validloader, position=1, leave=True)
+                ):
+                    # model.train(False)
+                    inputs = Variable(
+                        inputs.to(device, dtype=torch.float), requires_grad=True
+                    )
+                    labels = Variable(labels.to(device))
+
+                    pred = model(inputs)
+                    precision, recall, f1 = precision_recall(
+                        labels.float().view(-1, 1), pred
+                    )  # outputs = net(inputs)
+                    loss = criterion(pred, labels.float().view(-1, 1)).to(device)
+                    # loss = criterion(pred, labels).to(device)
+
+                    """valid record"""
+                    valid_loss += loss.item()
+                    valid_preds = (pred >= 0.5).float()
+                    valid_corrects += accuracy_score(labels.cpu(), valid_preds.cpu())
+                    valid_precision += precision.detach()
+                    valid_recall += recall.detach()
+                    valid_f1 += f1.detach()
+
+            """epoch valid record"""
+            epoch_valid_loss = valid_loss / len(validloader)
+            epoch_valid_precision = valid_precision / len(validloader)
+            epoch_valid_recall = valid_recall / len(validloader)
+            epoch_valid_f1 = valid_f1 / len(validloader)
+            epoch_valid_acc = valid_corrects / len(validloader)
+
+            globals()[f"{fold}_train_loss"].append(epoch_train_loss)
+            globals()[f"{fold}_train_precision"].append(epoch_train_precision)
+            globals()[f"{fold}_train_recall"].append(epoch_train_recall)
+            globals()[f"{fold}_train_f1"].append(epoch_train_f1)
+            globals()[f"{fold}_train_acc"].append(epoch_train_acc)
+
+            globals()[f"{fold}_valid_loss"].append(epoch_valid_loss)
+            globals()[f"{fold}_valid_precision"].append(epoch_valid_precision)
+            globals()[f"{fold}_valid_recall"].append(epoch_valid_recall)
+            globals()[f"{fold}_valid_f1"].append(epoch_valid_f1)
+            globals()[f"{fold}_valid_acc"].append(epoch_valid_acc)
+
+            if epoch_valid_loss < best_loss:
+                best_loss = epoch_valid_loss
+                best_model_weights = model.state_dict()
+            # valiid 1 epoch end
+            # 가장 최근 모델 저장
+            checkpoint = {
+                "epoch": epoch,
+                "loss": epoch_valid_loss,
+                "model": model,
+                # 'state_dict': model.module.state_dict(),
+                "state_dict": model.state_dict(),
+                "optimizer": optimizer.state_dict(),
+            }
+            torch.save(checkpoint, f"{config.save_dir}/{fold}fold_latest_epoch.pth")
+
+            # Earlystopping & best 모델 저장
+            savePath = "{}/{}fold_best_model.pth".format(wandb.config.save_dir, fold)
+            early_stopping(epoch_valid_loss, model, optimizer, savePath)
+            if early_stopping.early_stop:
+                print(
+                    f"Early stopping... fold:{fold} epoch:{epoch} loss:{epoch_valid_loss}"
+                )
+                break
+            # wandb.log({f'{config.data} : {fold}fold Validation loss': epoch_valid_loss, f'{fold}fold Learning_rate':optimizer.param_groups[0]['lr']})
+
+            wandb.log(
+                {
+                    f"{fold} fold train": {"loss": epoch_train_loss},
+                    f"{fold} fold val": {"loss": epoch_valid_loss},
+                    f"{fold} fold learning_rate": optimizer.param_groups[0]["lr"],
+                }
+            )
+            globals()[f"{fold}_lr"].append(optimizer.param_groups[0]["lr"])
+            scheduler.step(epoch_valid_loss)  # reduced는 무조건 epoch에서 backward
+            print("lr: ", optimizer.param_groups[0]["lr"])
+            print("-" * 60)
+            print()
+            # globals()[f'{fold}_result'].append(epoch_valid_loss)
+
+        torch.cuda.empty_cache()
+
+    plt.plot(globals()["0_valid_loss"], label="0fold")
+    plt.plot(globals()["1_valid_loss"], label="1fold")
+    plt.plot(globals()["2_valid_loss"], label="2fold")
+    plt.plot(globals()["3_valid_loss"], label="3fold")
+    plt.plot(globals()["4_valid_loss"], label="4fold")
+    plt.title("Validation loss")
+    plt.xlabel("epoch")
+    plt.ylabel("Validation loss")
+    plt.legend()
+    plt.show()
+    plt.savefig(config.save_dir + "/fig_saved.png")
+    # wandb.log({f'{config.data}': plt})
+    wandb.run.save()
+    wandb.finish()
+
+    print("Best val Loss: {:4f}".format(best_loss))
+    # load best model weights
+    model.load_state_dict(best_model_weights)
+    return model
+
+
+train_model_5cv()
diff --git a/utils.py b/utils.py
index be18dcb..a1f09bd 100644
--- a/utils.py
+++ b/utils.py
@@ -586,10 +586,11 @@ def efficientnet(
     num_classes=1,
 ):
     """Creates a efficientnet model."""
-
+    # 'r1_k3_s11_e1_i32_o16_se0.25',
+    #     'r2_k3_s22_e6_i16_o24_se0.25',
     blocks_args = [
-        "r1_ckh3_ckw1_pkh0_pkw1_csh1_csw1_psh3_psw1_e1_i8_o16_se0.25",
-        # "r1_ckh3_ckw1_pkh0_pkw0_csh1_csw1_psh2_psw1_e1_i4_o8_se0.25",
+        "r1_ckh5_ckw1_pkh0_pkw1_csh1_csw1_psh3_psw1_e1_i8_o6_se0.25",
+        # "r2_ckh3_ckw3_pkh0_pkw0_csh2_csw2_psh2_psw1_e6_i6_o1_se0.25",
         # "r1_ckh3_ckw3_pkh2_pkw2_csh1_csw1_psh2_psw2_e1_i8_o16_se0.25",
         # 'r3_k3_s22_e6_i40_o80_se0.25',
         # 'r3_k5_s11_e6_i80_o112_se0.25',
diff --git a/utils2.py b/utils2.py
index 2dc7f46..e94d35c 100644
--- a/utils2.py
+++ b/utils2.py
@@ -588,14 +588,13 @@ def efficientnet(
     """Creates a efficientnet model."""
 
     blocks_args = [
-        "r1_ckh5_ckw5_pkh0_pkw1_csh2_csw1_psh3_psw1_e1_i8_o16_se0.25",
-        # "r1_ckh3_ckw1_pkh0_pkw0_csh1_csw1_psh2_psw1_e1_i4_o8_se0.25",
-        # "r1_ckh3_ckw3_pkh2_pkw2_csh1_csw1_psh2_psw2_e1_i8_o16_se0.25",
-        # 'r3_k3_s22_e6_i40_o80_se0.25',
-        # 'r3_k5_s11_e6_i80_o112_se0.25',
-        # 'r4_k5_s22_e6_i112_o192_se0.25',
-        # 'r1_k3_s11_e6_i192_o320_se0.25',
-        # 'r1_k3_s11_e6_i24_o48_se0.25',
+        "r1_ckh5_ckw1_pkh0_pkw1_csh1_csw1_psh3_psw1_e1_i8_o6_se0.25",
+        # "r2_ckh3_ckw3_pkh0_pkw1_csh2_csw1_psh2_psw1_e6_i6_o12_se0.25",
+        # "r2_ckh5_ckw5_pkh0_pkw2_csh2_csw2_psh2_psw2_e6_i12_o30_se0.25",
+        # "r3_ckh3_ckw3_pkh0_pkw2_csh2_csw1_psh2_psw2_e6_i30_o60_se0.25",
+        # "r3_ckh5_ckw5_pkh0_pkw2_csh1_csw1_psh2_psw2_e6_i60_o90_se0.25",      
+        # "r4_ckh5_ckw5_pkh0_pkw2_csh2_csw2_psh2_psw2_e6_i90_o120_se0.25",
+        # "r1_ckh3_ckw3_pkh0_pkw2_csh1_csw1_psh2_psw2_e6_i120_o200_se0.25",
     ]
     blocks_args = BlockDecoder.decode(blocks_args)
 
diff --git a/utils3.py b/utils3.py
index 420c7c8..586a7c2 100644
--- a/utils3.py
+++ b/utils3.py
@@ -588,7 +588,7 @@ def efficientnet(
     """Creates a efficientnet model."""
 
     blocks_args = [
-        "r1_ckh5_ckw3_pkh0_pkw1_csh2_csw1_psh3_psw1_e1_i8_o16_se0.25",
+        "r1_ckh5_ckw1_pkh0_pkw1_csh1_csw1_psh3_psw1_e1_i8_o6_se0.25",
         # "r1_ckh3_ckw1_pkh0_pkw0_csh1_csw1_psh2_psw1_e1_i4_o8_se0.25",
         # "r1_ckh3_ckw3_pkh2_pkw2_csh1_csw1_psh2_psw2_e1_i8_o16_se0.25",
         # 'r3_k3_s22_e6_i40_o80_se0.25',
diff --git a/utils4.py b/utils4.py
index 9804976..4918ad4 100644
--- a/utils4.py
+++ b/utils4.py
@@ -588,7 +588,7 @@ def efficientnet(
     """Creates a efficientnet model."""
 
     blocks_args = [
-        "r1_ckh5_ckw1_pkh0_pkw1_csh2_csw1_psh3_psw1_e1_i8_o16_se0.25",
+        "r1_ckh5_ckw1_pkh0_pkw1_csh1_csw1_psh3_psw1_e1_i8_o6_se0.25",
         # "r1_ckh3_ckw1_pkh0_pkw0_csh1_csw1_psh2_psw1_e1_i4_o8_se0.25",
         # "r1_ckh3_ckw3_pkh2_pkw2_csh1_csw1_psh2_psw2_e1_i8_o16_se0.25",
         # 'r3_k3_s22_e6_i40_o80_se0.25',
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
index c3fa3a1..2df21a5 120000
--- a/wandb/debug-internal.log
+++ b/wandb/debug-internal.log
@@ -1 +1 @@
-run-20230515_170843-jr2qjj7w/logs/debug-internal.log
\ No newline at end of file
+run-20230518_125137-d94qvxh4/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
index e29b7be..a93e049 120000
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1 +1 @@
-run-20230515_170843-jr2qjj7w/logs/debug.log
\ No newline at end of file
+run-20230518_125137-d94qvxh4/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
index 8d3442e..7d68d2c 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20230515_170843-jr2qjj7w
\ No newline at end of file
+run-20230518_125137-d94qvxh4
\ No newline at end of file
