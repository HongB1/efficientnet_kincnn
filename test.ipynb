{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kincnn\n",
    "import torchvision\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/anaconda3/envs/phos/lib/python3.10/site-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/hb/anaconda3/envs/phos/lib/python3.10/site-packages/torch/onnx/utils.py:687: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/hb/anaconda3/envs/phos/lib/python3.10/site-packages/torch/onnx/utils.py:1178: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "model = kincnn.EfficientNet.from_name(\"efficientnet-phospho-B-15\")\n",
    "state_dict = torch.load(f'/home/hb/python/efficientnet_kincnn/saved_model/0517/DeepPP_kincnn1_1516_bs1024_weight0/0fold_best_model.pth')\n",
    "model.load_state_dict(state_dict['state_dict']) \n",
    "params = model.state_dict()\n",
    "dummy_data = torch.empty(1, 1, 263, 15  , dtype = torch.float32)\n",
    "torch.onnx.export(model, dummy_data, \"output.onnx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "Number of positive samples in training data: 1605 (50.03% of total)\n",
      "Number of positive samples in validation data: 395 (49.87% of total)\n"
     ]
    }
   ],
   "source": [
    "from prepare_dataset import prepare_dataset\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "data = prepare_dataset()\n",
    "train_set = data[0]\n",
    "valid_set = data[1]\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_set, batch_size=64, pin_memory=True, shuffle=True)\n",
    "valid_loader = data_utils.DataLoader(valid_set, batch_size=64,)\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "dataloaders = {'train':train_loader,'valid':valid_loader}\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'valid']}\n",
    "dataset = ConcatDataset([train_set, valid_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet-phospho-B-15\n",
      "3200\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=32, weight of size [32, 1, 3, 3], expected input[64, 8, 134, 17] to have 32 channels, but got 8 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Variable(inputs\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m labels \u001b[38;5;241m=\u001b[39m Variable(labels\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m---> 38\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/model.py:292\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# bs = inputs.size(0)\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# print(bs)\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# Convolution layers\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Pooling and final linear layer\u001b[39;00m\n\u001b[1;32m    295\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_avg_pooling(x)\n",
      "File \u001b[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/model.py:278\u001b[0m, in \u001b[0;36mEfficientNet.extract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_connect_rate:\n\u001b[1;32m    277\u001b[0m         drop_connect_rate \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(idx) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocks)\n\u001b[0;32m--> 278\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_connect_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_connect_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Head\u001b[39;00m\n\u001b[1;32m    281\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_head(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/model.py:91\u001b[0m, in \u001b[0;36mMBConvBlock.forward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m     88\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn0(x)\n\u001b[1;32m     89\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mish(x)\n\u001b[0;32m---> 91\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depthwise_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn1(x)\n\u001b[1;32m     93\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mish(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1510\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/utils.py:275\u001b[0m, in \u001b[0;36mConv2dStaticSamePadding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    274\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_padding(x)\n\u001b[0;32m--> 275\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=32, weight of size [32, 1, 3, 3], expected input[64, 8, 134, 17] to have 32 channels, but got 8 channels instead"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from model import EfficientNet\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    model = EfficientNet.from_name('efficientnet-phospho-B-15')\n",
    "    model = model.to(device)\n",
    "   # Define data loaders for training and testing data in this fold\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    print(len(train_idx))\n",
    "    print(len(valid_idx))\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                dataset,\n",
    "                batch_size=64, sampler=train_subsampler)\n",
    "    validloader = torch.utils.data.DataLoader(\n",
    "                dataset,\n",
    "                batch_size=64, sampler=test_subsampler)\n",
    "\n",
    "    for epoch in tqdm(range(20), position=0, leave=True):\n",
    "        # print('-' * 60)\n",
    "        # print('Epoch {}/{}'.format(epoch+1, 20))\n",
    "\n",
    "        train_corrects = 0.0\n",
    "        train_loss = 0.0\n",
    "        train_precision, train_recall, train_f1 = 0.0, 0.0, 0.0\n",
    "\n",
    "        for _, (inputs, labels) in enumerate(tqdm(trainloader, position=1, leave=True)):\n",
    "                model.train(True)\n",
    "                inputs = Variable(inputs.to(device, dtype=torch.float), requires_grad=True)\n",
    "                labels = Variable(labels.to(device))\n",
    "                pred = model(inputs) # forward"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
   "execution_count": 1,
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import re\n",
    "import collections\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import *\n",
    "from torch.nn import functional as F\n",
    "\n",
    "GlobalParams = collections.namedtuple(\n",
    "    \"GlobalParams\",\n",
    "    [\n",
    "        \"width_coefficient\",\n",
    "        \"depth_coefficient\",\n",
    "        \"image_size\",\n",
    "        \"dropout_rate\",\n",
    "        \"num_classes\",\n",
    "        \"batch_norm_momentum\",\n",
    "        \"batch_norm_epsilon\",\n",
    "        \"drop_connect_rate\",\n",
    "        \"depth_divisor\",\n",
    "        \"min_depth\",\n",
    "        \"include_top\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Parameters for an individual model block\n",
    "BlockArgs = collections.namedtuple(\n",
    "    \"BlockArgs\",\n",
    "    [\n",
    "        \"num_repeat\",\n",
    "        \"kernel_size\",\n",
    "        \"stride\",\n",
    "        \"expand_ratio\",\n",
    "        \"input_filters\",\n",
    "        \"output_filters\",\n",
    "        \"se_ratio\",\n",
    "        \"id_skip\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Set GlobalParams and BlockArgs's defaults\n",
    "GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def efficientnet(width_coefficient=None, depth_coefficient=None, dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2, image_size=None, num_classes=1):\n",
    "    \"\"\" Creates a efficientnet model. \"\"\"\n",
    "\n",
    "    blocks_args = [\n",
    "        'r1_kh8_kw2_sh2_sw2_e2_i8_o16_se0.25',\n",
    "        'r1_kh8_kw3_sh2_sw1_e2_i16_o32_se0.25',\n",
    "        'r1_kh6_kw3_sh2_sw2_e2_i32_o64_se0.25',\n",
    "        # 'r3_k3_s22_e6_i40_o80_se0.25',\n",
    "        # 'r3_k5_s11_e6_i80_o112_se0.25',\n",
    "        # 'r4_k5_s22_e6_i112_o192_se0.25',\n",
    "        # 'r1_k3_s11_e6_i192_o320_se0.25',\n",
    "        # 'r1_k3_s11_e6_i24_o48_se0.25',\n",
    "    ]\n",
    "    blocks_args = BlockDecoder.decode(blocks_args)\n",
    "\n",
    "    global_params = GlobalParams(\n",
    "        batch_norm_momentum=0.99,\n",
    "        batch_norm_epsilon=1e-3,\n",
    "        dropout_rate=dropout_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        # data_format='channels_last',  # removed, this is always true in PyTorch\n",
    "        num_classes=num_classes,\n",
    "        width_coefficient=width_coefficient,\n",
    "        depth_coefficient=depth_coefficient,\n",
    "        depth_divisor=8,\n",
    "        min_depth=None,\n",
    "        image_size=image_size,\n",
    "    )\n",
    "\n",
    "    return blocks_args, global_params\n",
    "\n",
=======
    "from utils import efficientnet\n",
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
    "blocks_args, global_params = efficientnet(width_coefficient=1.0, depth_coefficient=1.0, dropout_rate=0.7, image_size=[263, 15])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 2,
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalParams(width_coefficient=1.0, depth_coefficient=1.0, image_size=[263, 15], dropout_rate=0.7, num_classes=1, batch_norm_momentum=0.99, batch_norm_epsilon=0.001, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, include_top=None)\n",
      "\n",
      "MBConvblock 0:  BlockArgs(num_repeat=1, conv_kernel_size=(5, 1), pool_kernel_size=(3, 1), conv_stride=(1, 1), pool_stride=(3, 1), expand_ratio=1, input_filters=2, output_filters=4, se_ratio=0.25, id_skip=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(global_params)\n",
    "print()\n",
    "for idx, block_args in enumerate(blocks_args):\n",
    "    print(f'MBConvblock {idx}: ', block_args)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_output_image_size_(input_image_size, stride):\n",
    "    \"\"\"Calculates the output image size when using Conv2dSamePadding with a stride.\n",
    "       Necessary for static padding. Thanks to mannatsingh for pointing this out.\n",
    "\n",
    "    Args:\n",
    "        input_image_size (int, tuple or list): Size of input image.\n",
    "        stride (int, tuple or list): Conv2d operation's stride.\n",
    "\n",
    "    Returns:\n",
    "        output_image_size: A list [H,W].\n",
    "    \"\"\"\n",
    "    if input_image_size is None:\n",
    "        return None\n",
    "    image_height, image_width = get_width_and_height_from_size(input_image_size)\n",
    "    sh, sw = stride if type(stride) == (list) or (tuple) else [stride, stride]\n",
    "    # stride = stride if isinstance(stride, int) else stride[0]\n",
    "    image_height = int(math.ceil(image_height / sh))\n",
    "    image_width = int(math.ceil(image_width / sw))\n",
    "    return [image_height, image_width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
   "outputs": [],
   "source": [
    "from utils import Conv2dStaticSamePadding, MaxPool2dStaticSamePadding\n",
    "from functools import partial\n",
    "\n",
    "bn_mom = 1 - global_params.batch_norm_momentum\n",
    "bn_eps = global_params.batch_norm_epsilon\n",
    "image_size = global_params.image_size\n",
<<<<<<< HEAD
    "Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[132, 15]"
      ]
=======
    "Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "MaxPool2d = partial(MaxPool2dStaticSamePadding_, image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[263, 15]"
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from utils import round_filters, calculate_output_image_size, MemoryEfficientSwish\n",
    "\n",
    "# Stem\n",
    "image_size = [263, 15]\n",
    "in_channels = 1\n",
    "out_channels = round_filters(8, global_params)\n",
    "_conv_stem = Conv2d(in_channels, out_channels, kernel_size=(5, 1), stride=(1, 1), bias=False, image_size=image_size)\n",
    "_bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
<<<<<<< HEAD
    "image_size = calculate_output_image_size_(image_size, stride=(2, 1))\n",
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_swish = MemoryEfficientSwish()\n",
    "x0 = torch.randn((1, 1, 263, 15))\n",
    "x1 = _conv_stem(x0)\n",
    "x2 = _bn0(x1)\n",
    "x3 = _swish(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 132, 15])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBConvblock 0:  BlockArgs(num_repeat=1, kernel_size=(8, 2), stride=(2, 2), expand_ratio=2, input_filters=8, output_filters=16, se_ratio=0.25, id_skip=True)\n",
      "\n",
      "MBConvblock 1:  BlockArgs(num_repeat=1, kernel_size=(8, 3), stride=(2, 1), expand_ratio=2, input_filters=16, output_filters=32, se_ratio=0.25, id_skip=True)\n",
      "\n",
      "MBConvblock 2:  BlockArgs(num_repeat=1, kernel_size=(6, 3), stride=(2, 2), expand_ratio=2, input_filters=32, output_filters=64, se_ratio=0.25, id_skip=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, block_args in enumerate(blocks_args):\n",
    "    print(f'MBConvblock {idx}: ', block_args)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 263, 15 -> 132, 8 -> 64, 15 -> 32, 15 -> 17, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Mobile Inverted Residual Bottleneck Block\n",
    "    Args:\n",
    "        block_args (namedtuple): BlockArgs, see above\n",
    "        global_params (namedtuple): GlobalParam, see above\n",
    "    Attributes:\n",
    "        has_se (bool): Whether the block contains a Squeeze and Excitation layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block_args, global_params, image_size=None):\n",
    "        super().__init__()\n",
    "        self._block_args = block_args\n",
    "        self._bn_mom = 1 - global_params.batch_norm_momentum\n",
    "        self._bn_eps = global_params.batch_norm_epsilon\n",
    "        self.has_se = (self._block_args.se_ratio is not None) and (\n",
    "            0 < self._block_args.se_ratio <= 1\n",
    "        )\n",
    "        self.id_skip = block_args.id_skip  # skip connection and drop connect\n",
    "\n",
    "        # Expansion phase (Inverted Bottleneck)\n",
    "        inp = self._block_args.input_filters  # number of input channels\n",
    "        oup = (\n",
    "            self._block_args.input_filters * self._block_args.expand_ratio\n",
    "        )  # number of output channels\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "            self._expand_conv = Conv2d(\n",
    "                in_channels=inp, out_channels=oup, kernel_size=1, bias=False\n",
    "            )\n",
    "            self._bn0 = nn.BatchNorm2d(\n",
    "                num_features=oup, momentum=self._bn_mom, eps=self._bn_eps\n",
    "            )\n",
    "            # image_size = calculate_output_image_size(image_size, 1) <-- this wouldn't modify image_size\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        k = self._block_args.kernel_size\n",
    "        s = self._block_args.stride\n",
    "        Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "        self._depthwise_conv = Conv2d(\n",
    "            in_channels=oup,\n",
    "            out_channels=oup,\n",
    "            groups=oup,  # groups makes it depthwise\n",
    "            kernel_size=k,\n",
    "            stride=s,\n",
    "            bias=False,\n",
    "        )\n",
    "        self._bn1 = nn.BatchNorm2d(\n",
    "            num_features=oup, momentum=self._bn_mom, eps=self._bn_eps\n",
    "        )\n",
    "        image_size = calculate_output_image_size_(image_size, s)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            Conv2d = get_same_padding_conv2d(image_size=(1, 1))\n",
    "            num_squeezed_channels = max(\n",
    "                1, int(self._block_args.input_filters * self._block_args.se_ratio)\n",
    "            )\n",
    "            self._se_reduce = Conv2d(\n",
    "                in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1\n",
    "            )\n",
    "            self._se_expand = Conv2d(\n",
    "                in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1\n",
    "            )\n",
    "\n",
    "        # Output phase (Pointwise convolution phase)\n",
    "        final_oup = self._block_args.output_filters\n",
    "        Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "        self._project_conv = Conv2d(\n",
    "            in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False\n",
    "        )\n",
    "        self._bn2 = nn.BatchNorm2d(\n",
    "            num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps\n",
    "        )\n",
    "        self._swish = MemoryEfficientSwish()\n",
    "\n",
    "    def forward(self, inputs, drop_connect_rate=None):\n",
    "        \"\"\"\n",
    "        :param inputs: input tensor\n",
    "        :param drop_connect_rate: drop connect rate (float, between 0 and 1)\n",
    "        :return: output of block\n",
    "        \"\"\"\n",
    "\n",
    "        # Expansion and Depthwise Convolution\n",
    "        x = inputs\n",
    "        if self._block_args.expand_ratio != 1:\n",
    "            x = self._expand_conv(inputs)\n",
    "            x = self._bn0(x)\n",
    "            x = self._swish(x)\n",
    "\n",
    "        x = self._depthwise_conv(x)\n",
    "        x = self._bn1(x)\n",
    "        x = self._swish(x)\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "            x_squeezed = self._se_reduce(x_squeezed)\n",
    "            x_squeezed = self._swish(x_squeezed)\n",
    "            x_squeezed = self._se_expand(x_squeezed)\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "\n",
    "        # Pointwise Convolution\n",
    "        x = self._project_conv(x)\n",
    "        x = self._bn2(x)\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        input_filters, output_filters = (\n",
    "            self._block_args.input_filters,\n",
    "            self._block_args.output_filters,\n",
    "        )\n",
    "        if (\n",
    "            self.id_skip\n",
    "            and self._block_args.stride == 1\n",
    "            and input_filters == output_filters\n",
    "        ):\n",
    "            # The combination of skip connection and drop connect brings about stochastic depth.\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "            x = x + inputs  # skip connection\n",
    "        return x\n",
    "\n",
    "    def set_swish(self, memory_efficient=True):\n",
    "        \"\"\"Sets swish function as memory efficient (for training) or standard (for export).\n",
    "\n",
    "        Args:\n",
    "            memory_efficient (bool): Whether to use memory-efficient version of swish.\n",
    "        \"\"\"\n",
    "        self._swish = MemoryEfficientSwish() if memory_efficient else Swish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_bn_mom = 1 - global_params.batch_norm_momentum\n",
    "_bn_eps = global_params.batch_norm_epsilon\n",
    "\n",
    "has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n",
    "id_skip = block_args.id_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Expansion phase (Inverted Bottleneck)\n",
    "inp = block_args.input_filters  # number of input channels\n",
    "oup = (\n",
    "    block_args.input_filters * block_args.expand_ratio\n",
    ")  # number of output channels\n",
    "if block_args.expand_ratio != 1:\n",
    "    Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "    _expand_conv = Conv2d(\n",
    "        in_channels=inp, out_channels=oup, kernel_size=1, bias=False\n",
    "    )\n",
    "    _bn0 = nn.BatchNorm2d(\n",
    "        num_features=oup, momentum=_bn_mom, eps=_bn_eps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Depthwise convolution phase\n",
    "k = block_args.kernel_size\n",
    "s = block_args.stride\n",
    "Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "_depthwise_conv = Conv2d(\n",
    "    in_channels=oup,\n",
    "    out_channels=oup,\n",
    "    groups=oup,  # groups makes it depthwise\n",
    "    kernel_size=k,\n",
    "    stride=s,\n",
    "    bias=False,\n",
    ")\n",
    "_bn1 = nn.BatchNorm2d(\n",
    "    num_features=oup, momentum=_bn_mom, eps=_bn_eps\n",
    ")\n",
    "image_size = calculate_output_image_size_(image_size, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Squeeze and Excitation layer, if desired\n",
    "if has_se:\n",
    "    Conv2d = get_same_padding_conv2d(image_size=(1, 1))\n",
    "    num_squeezed_channels = max(\n",
    "        1, int(block_args.input_filters * block_args.se_ratio)\n",
    "    )\n",
    "    _se_reduce = Conv2d(\n",
    "        in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1\n",
    "    )\n",
    "    _se_expand = Conv2d(\n",
    "        in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1\n",
    "    )\n",
    "\n",
    "# Output phase (Pointwise convolution phase)\n",
    "final_oup = block_args.output_filters\n",
    "Conv2d = partial(Conv2dStaticSamePadding, image_size=image_size)\n",
    "_project_conv = Conv2d(\n",
    "    in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False\n",
    ")\n",
    "_bn2 = nn.BatchNorm2d(\n",
    "    num_features=final_oup, momentum=_bn_mom, eps=_bn_eps\n",
    ")\n",
    "_swish = MemoryEfficientSwish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlockArgs(num_repeat=1, kernel_size=(8, 2), stride=(2, 2), expand_ratio=1, input_filters=8, output_filters=16, se_ratio=0.25, id_skip=True)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = x3\n",
    "inputs.shape\n",
    "x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 66, 7])\n",
      "torch.Size([1, 8, 66, 7])\n",
      "torch.Size([1, 8, 66, 7])\n"
     ]
    }
   ],
   "source": [
    "x = _depthwise_conv(x)\n",
    "print(x.shape)\n",
    "x = _bn1(x)\n",
    "print(x.shape)\n",
    "x = _swish(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 1, 1])\n",
      "torch.Size([1, 2, 1, 1])\n",
      "torch.Size([1, 2, 1, 1])\n",
      "torch.Size([1, 8, 1, 1])\n",
      "torch.Size([1, 8, 66, 7])\n"
     ]
    }
   ],
   "source": [
    "if has_se:\n",
    "    x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "    print(x_squeezed.shape)\n",
    "    x_squeezed = _se_reduce(x_squeezed)\n",
    "    print(x_squeezed.shape)\n",
    "    x_squeezed = _swish(x_squeezed)\n",
    "    print(x_squeezed.shape)\n",
    "    x_squeezed = _se_expand(x_squeezed)\n",
    "    print(x_squeezed.shape)\n",
    "    x = torch.sigmoid(x_squeezed) * x\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 66, 7])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = _project_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 66, 7])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 66, 7])\n"
     ]
    }
   ],
   "source": [
    "# Pointwise Convolution\n",
    "# x = _project_conv\n",
    "\n",
    "x = _bn2(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 16)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip connection and drop connect\n",
    "input_filters, output_filters = (\n",
    "    block_args.input_filters,\n",
    "    block_args.output_filters,\n",
    ")\n",
    "input_filters, output_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if (\n",
    "    id_skip\n",
    "    and block_args.stride == 1\n",
    "    and input_filters == output_filters\n",
    "):\n",
    "    # The combination of skip connection and drop connect brings about stochastic depth.\n",
    "    if drop_connect_rate:\n",
    "        x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "    x = x + inputs  # skip connection\n",
    "return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  [132, 15]\n",
      "After:  [66, 8]\n",
      "Before:  [66, 8]\n",
      "After:  [33, 8]\n",
      "Before:  [33, 8]\n",
      "After:  [17, 4]\n"
     ]
    }
   ],
   "source": [
    "# MBConvBlock\n",
    "\n",
    "blocks = nn.ModuleList([])\n",
    "for block_args in blocks_args:\n",
    "    # Update block input and output filters based on depth multiplier.\n",
    "    block_args = block_args._replace(\n",
    "        input_filters=round_filters(\n",
    "            block_args.input_filters, global_params\n",
    "        ),\n",
    "        # input_filters=8,\n",
    "        output_filters=round_filters(\n",
    "            block_args.output_filters, global_params\n",
    "        ),\n",
    "        num_repeat=round_repeats(block_args.num_repeat, global_params),\n",
    "    )\n",
    "\n",
    "    # The first block needs to take care of stride and filter size increase.\n",
    "    blocks.append(\n",
    "        MBConvBlock(block_args, global_params, image_size=image_size)\n",
    "    )\n",
    "    print('Before: ', image_size)\n",
    "    image_size = calculate_output_image_size_(image_size, block_args.stride)\n",
    "    print('After: ', image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 4]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
=======
    "_max_pool = MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n",
    "_swish = MemoryEfficientSwish()\n",
    "image_size = calculate_output_image_size(image_size, stride=(1, 1))\n",
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
    "image_size"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Head\n",
    "in_channels = block_args.output_filters  # output of final block\n",
    "out_channels = round_filters(128, global_params)\n",
    "_conv_head = Conv2d(in_channels, out_channels, kernel_size=(2, 1), bias=False)\n",
    "_bn1 = nn.BatchNorm2d(\n",
    "    num_features=out_channels, momentum=bn_mom, eps=bn_eps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_dropout = nn.Dropout(global_params.dropout_rate)\n",
    "_fc = nn.Linear(out_channels, global_params.num_classes)\n",
    "\n",
    "# set activation to memory efficient swish by default\n",
    "_swish = MemoryEfficientSwish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 132, 15])"
      ]
=======
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import kincnn\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 263, 15)\n",
    "model = kincnn.EfficientNet.from_name('efficientnet-phospho-B-15')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.6308]], grad_fn=<SigmoidBackward0>)"
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Stem\n",
    "x0 = torch.randn((1, 1, 263, 15))\n",
    "x1 = _conv_stem(x0)\n",
    "x2 = _bn0(x1)\n",
    "x3 = _swish(x2)\n",
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
=======
    "model(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pytorch_model_summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "                    Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=====================================================================================\n",
      "                     ZeroPad2d-1     [1, 1, 263, 15]               0               0\n",
      "                   BatchNorm2d-2     [1, 8, 263, 15]              16              16\n",
      "                     ZeroPad2d-3     [1, 8, 263, 15]               0               0\n",
      "          MemoryEfficientSwish-4     [1, 8, 132, 15]               0               0\n",
      "       Conv2dStaticSamePadding-5     [1, 8, 132, 15]              40              40\n",
      "                   BatchNorm2d-6     [1, 8, 132, 15]              16              16\n",
      "    MaxPool2dStaticSamePadding-7     [1, 8, 132, 15]               0               0\n",
      "          MemoryEfficientSwish-8      [1, 8, 44, 15]               0               0\n",
      "       Conv2dStaticSamePadding-9        [1, 8, 1, 1]              18              18\n",
      "      Conv2dStaticSamePadding-10        [1, 2, 1, 1]              24              24\n",
      "      Conv2dStaticSamePadding-11      [1, 8, 44, 15]              64              64\n",
      "                  BatchNorm2d-12      [1, 8, 44, 15]              16              16\n",
      "      Conv2dStaticSamePadding-13      [1, 8, 44, 15]              24              24\n",
      "                  BatchNorm2d-14      [1, 8, 44, 15]              16              16\n",
      "   MaxPool2dStaticSamePadding-15      [1, 8, 44, 15]               0               0\n",
      "         MemoryEfficientSwish-16      [1, 8, 22, 15]               0               0\n",
      "      Conv2dStaticSamePadding-17        [1, 8, 1, 1]              18              18\n",
      "      Conv2dStaticSamePadding-18        [1, 2, 1, 1]              24              24\n",
      "      Conv2dStaticSamePadding-19      [1, 8, 22, 15]             128             128\n",
      "                  BatchNorm2d-20     [1, 16, 22, 15]              32              32\n",
      "      Conv2dStaticSamePadding-21     [1, 16, 22, 15]             144             144\n",
      "                  BatchNorm2d-22     [1, 16, 22, 15]              32              32\n",
      "   MaxPool2dStaticSamePadding-23     [1, 16, 22, 15]               0               0\n",
      "         MemoryEfficientSwish-24      [1, 16, 11, 8]               0               0\n",
      "      Conv2dStaticSamePadding-25       [1, 16, 1, 1]              68              68\n",
      "      Conv2dStaticSamePadding-26        [1, 4, 1, 1]              80              80\n",
      "      Conv2dStaticSamePadding-27      [1, 16, 11, 8]             512             512\n",
      "                  BatchNorm2d-28      [1, 32, 11, 8]              64              64\n",
      "                     Identity-29      [1, 32, 11, 8]               0               0\n",
      "                  BatchNorm2d-30       [1, 8, 11, 8]              16              16\n",
      "            AdaptiveAvgPool2d-31       [1, 8, 11, 8]               0               0\n",
      "                      Dropout-32              [1, 8]               0               0\n",
      "                       Linear-33              [1, 8]               9               9\n",
      "=====================================================================================\n",
      "Total params: 1,361\n",
      "Trainable params: 1,361\n",
      "Non-trainable params: 0\n",
      "Batch size: 1\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "print(len(blocks))\n",
    "\n",
    "for idx, block in enumerate(blocks):\n",
    "    print(x.shape)\n",
    "    drop_connect_rate = global_params.drop_connect_rate\n",
    "    if drop_connect_rate:\n",
    "        drop_connect_rate *= float(idx) / len(blocks)\n",
    "    x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 17, 4])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlockArgs(num_repeat=1, kernel_size=(6, 3), stride=(2, 2), expand_ratio=2, input_filters=32, output_filters=64, se_ratio=0.25, id_skip=True)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_channels = block_args.output_filters  # output of final block\n",
    "out_channels = round_filters(128, global_params)\n",
    "# out_channels = round_filters(1280, self._global_params) <-- 원본\n",
    "# out_channels = 1280\n",
    "_conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "_bn1 = nn.BatchNorm2d(\n",
    "    num_features=out_channels, momentum=bn_mom, eps=bn_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 17, 4])"
      ]
=======
    "print(pytorch_model_summary.summary(model, torch.zeros(1, 1, 263, 15), show_input=True, show_hierarchical=False, max_depth=2, batch_size=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 1, 1, 267, 15]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchsummary\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary\n\u001B[0;32m----> 2\u001B[0m \u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m263\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torchsummary/torchsummary.py:72\u001B[0m, in \u001B[0;36msummary\u001B[0;34m(model, input_size, batch_size, device)\u001B[0m\n\u001B[1;32m     68\u001B[0m model\u001B[38;5;241m.\u001B[39mapply(register_hook)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# make a forward pass\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# print(x.shape)\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# remove these hooks\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m h \u001B[38;5;129;01min\u001B[39;00m hooks:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1509\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1510\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/kincnn.py:344\u001B[0m, in \u001B[0;36mEfficientNet.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls extract_features to extract features, applies final linear layer, and returns logits.\"\"\"\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;66;03m# bs = inputs.size(0)\u001B[39;00m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;66;03m# print(bs)\u001B[39;00m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;66;03m# Convolution layers\u001B[39;00m\n\u001B[0;32m--> 344\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# Pooling and final linear layer\u001B[39;00m\n\u001B[1;32m    347\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_avg_pooling(x)\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/kincnn.py:320\u001B[0m, in \u001B[0;36mEfficientNet.extract_features\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns output of the final convolution layer\"\"\"\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;66;03m# Stem\u001B[39;00m\n\u001B[0;32m--> 320\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_stem\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bn0(x)\n\u001B[1;32m    322\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_pooling(x)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1548\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1545\u001B[0m     bw_hook \u001B[38;5;241m=\u001B[39m hooks\u001B[38;5;241m.\u001B[39mBackwardHook(\u001B[38;5;28mself\u001B[39m, full_backward_hooks, backward_pre_hooks)\n\u001B[1;32m   1546\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[0;32m-> 1548\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1549\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n\u001B[1;32m   1550\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook_id, hook \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[1;32m   1551\u001B[0m         \u001B[38;5;241m*\u001B[39m_global_forward_hooks\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[1;32m   1552\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[1;32m   1553\u001B[0m     ):\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/utils.py:338\u001B[0m, in \u001B[0;36mConv2dStaticSamePadding.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    336\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    337\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatic_padding(x)\n\u001B[0;32m--> 338\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [2, 1, 1, 267, 15]"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 1, 263, 15))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from utils import round_filters\n",
    "out_channels = round_filters(\n",
    "            2, global_params\n",
    "        )  # number of output channels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "GlobalParams(width_coefficient=1.0, depth_coefficient=1.0, image_size=[263, 15], dropout_rate=0.7, num_classes=1, batch_norm_momentum=0.99, batch_norm_epsilon=0.001, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, include_top=None)"
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "x = _conv_head(x)\n",
    "x = _bn1(x)\n",
    "x = _swish(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x = _avg_pooling(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
=======
    "global_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_channels"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "_dropout = nn.Dropout(global_params.dropout_rate)\n",
    "_fc = nn.Linear(out_channels, global_params.num_classes)\n",
    "\n",
    "# set activation to memory efficient swish by default\n",
    "_swish = MemoryEfficientSwish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_copy = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3333]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = _avg_pooling(x)\n",
    "y = y.flatten(start_dim=1)\n",
    "y = _dropout(y)\n",
    "y = _fc(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = y.view(1, -1)\n",
    "y.shape\n",
    "# print(x.shape)\n",
    "\n",
    "# x = x.flatten(start_dim=1)\n",
    "# x = self._dropout(x)\n",
    "\n",
    "# x = self._fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1952, 0.2066, 0.1998, 0.2097, 0.2002, 0.2060, 0.2034, 0.2010, 0.1997,\n",
       "         0.2035, 0.2030, 0.1976, 0.1983, 0.1964, 0.2027, 0.2046, 0.2035, 0.2029,\n",
       "         0.2082, 0.2109, 0.2003, 0.2054, 0.2026, 0.2103, 0.1970, 0.2057, 0.1945,\n",
       "         0.2000, 0.1880, 0.2057, 0.1968, 0.2006, 0.2054, 0.2093, 0.1914, 0.2065,\n",
       "         0.2077, 0.2035, 0.2096, 0.1974, 0.2065, 0.1984, 0.2047, 0.2102, 0.2056,\n",
       "         0.2111, 0.2112, 0.2067, 0.2039, 0.2021, 0.2035, 0.2015, 0.1834, 0.1905,\n",
       "         0.2059, 0.2052, 0.2052, 0.1892, 0.2001, 0.1991, 0.2050, 0.2024, 0.2093,\n",
       "         0.2104, 0.2007, 0.2100, 0.1988, 0.1895, 0.1999, 0.2009, 0.2069, 0.2135,\n",
       "         0.1948, 0.2116, 0.1986, 0.1980, 0.1937, 0.1970, 0.2007, 0.2006, 0.1952,\n",
       "         0.2038, 0.2047, 0.2028, 0.1999, 0.1964, 0.2048, 0.2022, 0.2015, 0.2061,\n",
       "         0.2032, 0.2024, 0.1970, 0.1846, 0.1995, 0.1991, 0.2061, 0.2078, 0.1917,\n",
       "         0.2001, 0.2058, 0.1946, 0.2025, 0.1998, 0.2066, 0.2030, 0.1995, 0.2035,\n",
       "         0.1996, 0.2079, 0.1934, 0.2043, 0.2035, 0.2096, 0.2030, 0.2057, 0.2047,\n",
       "         0.2009, 0.2005, 0.2158, 0.2031, 0.1896, 0.2059, 0.2012, 0.2117, 0.2055,\n",
       "         0.2035, 0.2006]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hb/python/efficientnet_kincnn/..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    1, 8, kernel_size=(15, 1), stride=(2, 1), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 0, 7, 7))\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(8, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        16, 16, kernel_size=(8, 2), stride=(2, 2), groups=16, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 3, 3))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        16, 2, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        2, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(8, 3), stride=(2, 1), groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 3, 3))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        64, 64, kernel_size=(6, 3), stride=(2, 2), groups=64, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 2, 3))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        64, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(8, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.7, inplace=False)\n",
       "  (_fc): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import efficientnet_kincnn\n",
    "import torch\n",
    "model = efficientnet_kincnn.EfficientNet.from_name('efficientnet-phospho-B-15')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kk\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    print('kk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    1, 8, kernel_size=(15, 1), stride=(2, 1), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 0, 7, 7))\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(8, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        16, 16, kernel_size=(8, 2), stride=(2, 2), groups=16, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 3, 3))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        16, 2, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        2, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(8, 3), stride=(2, 1), groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 3, 3))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        64, 64, kernel_size=(6, 3), stride=(2, 2), groups=64, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 2, 3))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        64, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(8, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.7, inplace=False)\n",
       "  (_fc): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.randn((1, 1, 263, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summary(model, input_size\u001b[39m=\u001b[39m(\u001b[39m1024\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m263\u001b[39m, \u001b[39m15\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1024, 1, 263, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 1, 15, 1], expected input[1, 2, 277, 15] to have 1 channels, but got 2 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torchsummary\u001b[39m.\u001b[39;49msummary(model, input_size\u001b[39m=\u001b[39;49m(\u001b[39m263\u001b[39;49m, \u001b[39m15\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/phos/lib/python3.10/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/phos/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python/efficientnet_kincnn/../efficientnet_kincnn/kincnn.py:336\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m\"\"\"Calls extract_features to extract features, applies final linear layer, and returns logits.\"\"\"\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m# bs = inputs.size(0)\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m# print(bs)\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39m# Convolution layers\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(inputs)\n\u001b[1;32m    338\u001b[0m \u001b[39m# Pooling and final linear layer\u001b[39;00m\n\u001b[1;32m    339\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_avg_pooling(x)\n",
      "File \u001b[0;32m~/python/efficientnet_kincnn/../efficientnet_kincnn/kincnn.py:313\u001b[0m, in \u001b[0;36mEfficientNet.extract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39m\"\"\"Returns output of the final convolution layer\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# Stem\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_stem(inputs)\n\u001b[1;32m    314\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bn0(x)\n\u001b[1;32m    315\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swish(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/phos/lib/python3.10/site-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/python/efficientnet_kincnn/utils.py:379\u001b[0m, in \u001b[0;36mConv2dStaticSamePadding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    378\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatic_padding(x)\n\u001b[0;32m--> 379\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mconv2d(\n\u001b[1;32m    380\u001b[0m         x,\n\u001b[1;32m    381\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    383\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    384\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[1;32m    385\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation,\n\u001b[1;32m    386\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups,\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 1, 15, 1], expected input[1, 2, 277, 15] to have 1 channels, but got 2 channels instead"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model, input_size=(263, 15))"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> 7d235b7e18d2f60ff0dc8e254a1387c542004c24
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
