{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from prepare_dataset import prepare_dataset\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "data = prepare_dataset()\n",
    "train_set = data[0]\n",
    "valid_set = data[1]\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_set, batch_size=64, pin_memory=True, shuffle=True)\n",
    "valid_loader = data_utils.DataLoader(valid_set, batch_size=64,)\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "dataloaders = {'train':train_loader,'valid':valid_loader}\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'valid']}\n",
    "dataset = ConcatDataset([train_set, valid_set])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet-phospho-B-15\n",
      "13730\n",
      "3433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=32, weight of size [32, 1, 3, 3], expected input[64, 8, 134, 17] to have 32 channels, but got 8 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m inputs \u001B[38;5;241m=\u001B[39m Variable(inputs\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat), requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     37\u001B[0m labels \u001B[38;5;241m=\u001B[39m Variable(labels\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[0;32m---> 38\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1509\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1510\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet/model.py:292\u001B[0m, in \u001B[0;36mEfficientNet.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# bs = inputs.size(0)\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;66;03m# print(bs)\u001B[39;00m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;66;03m# Convolution layers\u001B[39;00m\n\u001B[0;32m--> 292\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;66;03m# Pooling and final linear layer\u001B[39;00m\n\u001B[1;32m    295\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_avg_pooling(x)\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet/model.py:278\u001B[0m, in \u001B[0;36mEfficientNet.extract_features\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drop_connect_rate:\n\u001B[1;32m    277\u001B[0m         drop_connect_rate \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(idx) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blocks)\n\u001B[0;32m--> 278\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdrop_connect_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_connect_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;66;03m# Head\u001B[39;00m\n\u001B[1;32m    281\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_head(x)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1509\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1510\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet/model.py:91\u001B[0m, in \u001B[0;36mMBConvBlock.forward\u001B[0;34m(self, inputs, drop_connect_rate)\u001B[0m\n\u001B[1;32m     88\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bn0(x)\n\u001B[1;32m     89\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mish(x)\n\u001B[0;32m---> 91\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_depthwise_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bn1(x)\n\u001B[1;32m     93\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mish(x)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1509\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1510\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet/utils.py:275\u001B[0m, in \u001B[0;36mConv2dStaticSamePadding.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    274\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatic_padding(x)\n\u001B[0;32m--> 275\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given groups=32, weight of size [32, 1, 3, 3], expected input[64, 8, 134, 17] to have 32 channels, but got 8 channels instead"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from model import EfficientNet\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    model = EfficientNet.from_name('efficientnet-phospho-B-15')\n",
    "    model = model.to(device)\n",
    "   # Define data loaders for training and testing data in this fold\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    print(len(train_idx))\n",
    "    print(len(valid_idx))\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                dataset,\n",
    "                batch_size=64, sampler=train_subsampler)\n",
    "    validloader = torch.utils.data.DataLoader(\n",
    "                dataset,\n",
    "                batch_size=64, sampler=test_subsampler)\n",
    "\n",
    "    for epoch in tqdm(range(20), position=0, leave=True):\n",
    "        # print('-' * 60)\n",
    "        # print('Epoch {}/{}'.format(epoch+1, 20))\n",
    "\n",
    "        train_corrects = 0.0\n",
    "        train_loss = 0.0\n",
    "        train_precision, train_recall, train_f1 = 0.0, 0.0, 0.0\n",
    "\n",
    "        for _, (inputs, labels) in enumerate(tqdm(trainloader, position=1, leave=True)):\n",
    "                model.train(True)\n",
    "                inputs = Variable(inputs.to(device, dtype=torch.float), requires_grad=True)\n",
    "                labels = Variable(labels.to(device))\n",
    "                pred = model(inputs) # forward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 1, 263, 15])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import *\n",
    "from torch.nn import functional as F\n",
    "\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'stride', 'se_ratio'])\n",
    "\n",
    "# Change namedtuple defaults\n",
    "# GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def efficientnet(width_coefficient=None, depth_coefficient=None, dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2, image_size=None, num_classes=1):\n",
    "    \"\"\" Creates a efficientnet model. \"\"\"\n",
    "\n",
    "    blocks_args = [\n",
    "        'r1_k3_s11_e1_i32_o16_se0.25',\n",
    "        'r2_k3_s22_e6_i16_o24_se0.25',\n",
    "        'r1_k5_s22_e6_i24_o40_se0.25',\n",
    "        # 'r3_k3_s22_e6_i40_o80_se0.25',\n",
    "        # 'r3_k5_s11_e6_i80_o112_se0.25',\n",
    "        # 'r4_k5_s22_e6_i112_o192_se0.25',\n",
    "        # 'r1_k3_s11_e6_i192_o320_se0.25',\n",
    "        # 'r1_k3_s11_e6_i24_o48_se0.25',\n",
    "    ]\n",
    "    blocks_args = BlockDecoder.decode(blocks_args)\n",
    "\n",
    "    global_params = GlobalParams(\n",
    "        batch_norm_momentum=0.99,\n",
    "        batch_norm_epsilon=1e-3,\n",
    "        dropout_rate=dropout_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        # data_format='channels_last',  # removed, this is always true in PyTorch\n",
    "        num_classes=num_classes,\n",
    "        width_coefficient=width_coefficient,\n",
    "        depth_coefficient=depth_coefficient,\n",
    "        depth_divisor=8,\n",
    "        min_depth=None,\n",
    "        image_size=image_size,\n",
    "    )\n",
    "\n",
    "    return blocks_args, global_params\n",
    "\n",
    "blocks_args, global_params = efficientnet(width_coefficient=1.0, depth_coefficient=1.0, dropout_rate=0.7, image_size=[263, 15])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def _decode_block_string(block_string):\n",
    "    \"\"\" Gets a block through a string notation of arguments. \"\"\"\n",
    "    assert isinstance(block_string, str)\n",
    "\n",
    "    ops = block_string.split('_')\n",
    "    options = {}\n",
    "    for op in ops:\n",
    "        splits = re.split(r'(\\d.*)', op)\n",
    "        if len(splits) >= 2:\n",
    "            key, value = splits[:2]\n",
    "            options[key] = value\n",
    "\n",
    "    # Check stride\n",
    "    # assert (('s' in options and len(options['s']) == 1) or\n",
    "    #         (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\n",
    "    assert (len(options['k']) < 4) and (len(options['s']) < 4), 'stride 또는 kernel_size를 조정하세요'\n",
    "    if len(options['k'])>=2:\n",
    "        kernel_size = (int(options['k'][:-1]), int(options['k'][-1]))\n",
    "    else:\n",
    "        kernel_size = (int(options['k']),int(options['k']))\n",
    "\n",
    "\n",
    "    if len(options['s'])>=2:\n",
    "        stride = (int(options['s'][:-1]), int(options['s'][-1]))\n",
    "    else:\n",
    "        stride = (int(options['s']), int(options['s']))\n",
    "\n",
    "    return BlockArgs(\n",
    "        kernel_size=kernel_size,\n",
    "        num_repeat=int(options['r']),\n",
    "        input_filters=int(options['i']),\n",
    "        output_filters=int(options['o']),\n",
    "        expand_ratio=int(options['e']),\n",
    "        id_skip=('noskip' not in block_string),\n",
    "        se_ratio=float(options['se']) if 'se' in options else None,\n",
    "        stride=stride)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "BlockArgs(kernel_size=(22, 3), num_repeat=1, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, stride=(22, 4), se_ratio=0.25)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_decode_block_string('r1_k223_s224_e1_i32_o16_se0.25')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "stride 또는 kernel_size를 조정하세요",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m stride \u001B[38;5;241m=\u001B[39m \u001B[43m_decode_block_string\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr1_k3_s2221_e1_i32_o16_se0.25\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstride\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(stride)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mlen\u001B[39m(stride)\n",
      "Cell \u001B[0;32mIn[28], line 16\u001B[0m, in \u001B[0;36m_decode_block_string\u001B[0;34m(block_string)\u001B[0m\n\u001B[1;32m     11\u001B[0m         options[key] \u001B[38;5;241m=\u001B[39m value\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Check stride\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# assert (('s' in options and len(options['s']) == 1) or\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m#         (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(options[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m4\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(options[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m4\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstride 또는 kernel_size를 조정하세요\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(options[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m     18\u001B[0m     kernel_size \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mint\u001B[39m(options[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m'\u001B[39m][:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]), \u001B[38;5;28mint\u001B[39m(options[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]))\n",
      "\u001B[0;31mAssertionError\u001B[0m: stride 또는 kernel_size를 조정하세요"
     ]
    }
   ],
   "source": [
    "stride = _decode_block_string('r1_k3_s2221_e1_i32_o16_se0.25').stride\n",
    "print(stride)\n",
    "len(stride)\n",
    "\n",
    "# stride = stride if len(stride) == 2 else [stride[0]] * 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "(GlobalParams(width_coefficient=1.0, depth_coefficient=1.0, image_size=[263, 15], dropout_rate=0.7, num_classes=1, batch_norm_momentum=0.99, batch_norm_epsilon=0.001, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, include_top=None),\n [BlockArgs(num_repeat=1, kernel_size=3, stride=[1], expand_ratio=1, input_filters=32, output_filters=16, se_ratio=0.25, id_skip=True),\n  BlockArgs(num_repeat=2, kernel_size=3, stride=[2], expand_ratio=6, input_filters=16, output_filters=24, se_ratio=0.25, id_skip=True),\n  BlockArgs(num_repeat=1, kernel_size=5, stride=[2], expand_ratio=6, input_filters=24, output_filters=40, se_ratio=0.25, id_skip=True)])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_params, blocks_args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Conv2dStaticSamePadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow, for a fixed image size\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, image_size=None, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, kernel_size,  **kwargs)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n",
    "\n",
    "        # Calculate padding based on image size and save it\n",
    "        assert image_size is not None\n",
    "        ih, iw = image_size if type(image_size) == list else [image_size, image_size]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))\n",
    "        else:\n",
    "            self.static_padding = nn.Identity()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263, 15]\n",
      "functools.partial(<class 'utils.Conv2dStaticSamePadding'>, image_size=[263, 15])\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "bn_mom = 1 - global_params.batch_norm_momentum\n",
    "bn_eps = global_params.batch_norm_epsilon\n",
    "image_size = global_params.image_size\n",
    "Conv2d = get_same_padding_conv2d(image_size=image_size)\n",
    "in_channels = 1\n",
    "out_channels = round_filters(8, global_params)\n",
    "print(image_size)\n",
    "print(Conv2d)\n",
    "print(out_channels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "_conv_stem = Conv2d(in_channels, out_channels, kernel_size=(15, 1), stride=(2, 1), bias=False)\n",
    "_bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "image_size = calculate_output_image_size(image_size, stride=(2, 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_output_image_size(input_image_size, stride):\n",
    "    \"\"\"Calculates the output image size when using Conv2dSamePadding with a stride.\n",
    "       Necessary for static padding. Thanks to mannatsingh for pointing this out.\n",
    "\n",
    "    Args:\n",
    "        input_image_size (int, tuple or list): Size of input image.\n",
    "        stride (int, tuple or list): Conv2d operation's stride.\n",
    "\n",
    "    Returns:\n",
    "        output_image_size: A list [H,W].\n",
    "    \"\"\"\n",
    "    if input_image_size is None:\n",
    "        return None\n",
    "    image_height, image_width = get_width_and_height_from_size(input_image_size)\n",
    "    stride = stride if isinstance(stride, int) else stride[0]\n",
    "    image_height = int(math.ceil(image_height / stride))\n",
    "    image_width = int(math.ceil(image_width / stride))\n",
    "    return [image_height, image_width]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "stride = (2, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert (len(options['k']) < 4) and (len(options['s']) < 4), 'stride 또는 kernel_size를 조정하세요'\n",
    "if len(options['k'])>=2:\n",
    "    kernel_size = (int(options['k'][:-1]), int(options['k'][-1]))\n",
    "else:\n",
    "    kernel_size = (int(options['k']),int(options['k']))\n",
    "\n",
    "\n",
    "if len(options['s'])>=2:\n",
    "    stride = (int(options['s'][:-1]), int(options['s'][-1]))\n",
    "else:\n",
    "    stride = (int(options['s']), int(options['s']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "image_height, image_width = get_width_and_height_from_size([263, 15])\n",
    "image_height, image_width\n",
    "stride = stride if not isinstance(stride, int) else stride[0]\n",
    "image_height = int(math.ceil(image_height / stride))\n",
    "image_width = int(math.ceil(image_width / stride))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(stride, int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[66, 4]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_channels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "bn_mom = 1 - global_params.batch_norm_momentum\n",
    "bn_eps = global_params.batch_norm_epsilon\n",
    "\n",
    "# Get static or dynamic convolution depending on image size\n",
    "image_size = global_params.image_size\n",
    "Conv2d = get_same_padding_conv2d(image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "Conv2dStaticSamePadding(\n  1, 8, kernel_size=(15, 1), stride=(2, 1), bias=False\n  (static_padding): ZeroPad2d((0, 0, 7, 7))\n)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_conv_stem = Conv2d(in_channels, out_channels, kernel_size=(15, 1), stride=(2, 1),bias=False)\n",
    "_conv_stem"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
