{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "Number of positive samples in training data: 1605 (50.03% of total)\n",
      "Number of positive samples in validation data: 395 (49.87% of total)\n"
     ]
    }
   ],
   "source": [
    "from prepare_dataset import prepare_dataset\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "data = prepare_dataset()\n",
    "train_set = data[0]\n",
    "valid_set = data[1]\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_set, batch_size=64, pin_memory=True, shuffle=True)\n",
    "valid_loader = data_utils.DataLoader(valid_set, batch_size=64,)\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "dataloaders = {'train':train_loader,'valid':valid_loader}\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'valid']}\n",
    "dataset = ConcatDataset([train_set, valid_set])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet-phospho-B-15\n",
      "3200\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=32, weight of size [32, 1, 3, 3], expected input[64, 8, 134, 17] to have 32 channels, but got 8 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m inputs \u001B[38;5;241m=\u001B[39m Variable(inputs\u001B[38;5;241m.\u001B[39mto(device, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat), requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     37\u001B[0m labels \u001B[38;5;241m=\u001B[39m Variable(labels\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[0;32m---> 38\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1509\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1510\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/model.py:292\u001B[0m, in \u001B[0;36mEfficientNet.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# bs = inputs.size(0)\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;66;03m# print(bs)\u001B[39;00m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;66;03m# Convolution layers\u001B[39;00m\n\u001B[0;32m--> 292\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;66;03m# Pooling and final linear layer\u001B[39;00m\n\u001B[1;32m    295\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_avg_pooling(x)\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/model.py:278\u001B[0m, in \u001B[0;36mEfficientNet.extract_features\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drop_connect_rate:\n\u001B[1;32m    277\u001B[0m         drop_connect_rate \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(idx) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blocks)\n\u001B[0;32m--> 278\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdrop_connect_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_connect_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;66;03m# Head\u001B[39;00m\n\u001B[1;32m    281\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_head(x)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1509\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1510\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/model.py:91\u001B[0m, in \u001B[0;36mMBConvBlock.forward\u001B[0;34m(self, inputs, drop_connect_rate)\u001B[0m\n\u001B[1;32m     88\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bn0(x)\n\u001B[1;32m     89\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mish(x)\n\u001B[0;32m---> 91\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_depthwise_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bn1(x)\n\u001B[1;32m     93\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mish(x)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1502\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/efficientnet/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1506\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1509\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1510\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1512\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/Users/hb/Dropbox/github/efficientnet_kincnn/utils.py:275\u001B[0m, in \u001B[0;36mConv2dStaticSamePadding.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    274\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatic_padding(x)\n\u001B[0;32m--> 275\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Given groups=32, weight of size [32, 1, 3, 3], expected input[64, 8, 134, 17] to have 32 channels, but got 8 channels instead"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from model import EfficientNet\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    model = EfficientNet.from_name('efficientnet-phospho-B-15')\n",
    "    model = model.to(device)\n",
    "   # Define data loaders for training and testing data in this fold\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    print(len(train_idx))\n",
    "    print(len(valid_idx))\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                dataset,\n",
    "                batch_size=64, sampler=train_subsampler)\n",
    "    validloader = torch.utils.data.DataLoader(\n",
    "                dataset,\n",
    "                batch_size=64, sampler=test_subsampler)\n",
    "\n",
    "    for epoch in tqdm(range(20), position=0, leave=True):\n",
    "        # print('-' * 60)\n",
    "        # print('Epoch {}/{}'.format(epoch+1, 20))\n",
    "\n",
    "        train_corrects = 0.0\n",
    "        train_loss = 0.0\n",
    "        train_precision, train_recall, train_f1 = 0.0, 0.0, 0.0\n",
    "\n",
    "        for _, (inputs, labels) in enumerate(tqdm(trainloader, position=1, leave=True)):\n",
    "                model.train(True)\n",
    "                inputs = Variable(inputs.to(device, dtype=torch.float), requires_grad=True)\n",
    "                labels = Variable(labels.to(device))\n",
    "                pred = model(inputs) # forward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import *\n",
    "from torch.nn import functional as F\n",
    "\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'stride', 'se_ratio'])\n",
    "\n",
    "# Change namedtuple defaults\n",
    "# GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def efficientnet(width_coefficient=None, depth_coefficient=None, dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2, image_size=None, num_classes=1):\n",
    "    \"\"\" Creates a efficientnet model. \"\"\"\n",
    "\n",
    "    blocks_args = [\n",
    "        'r1_k3_s11_e1_i8_o16_se0.25',\n",
    "        'r1_k3_s22_e6_i16_o32_se0.25',\n",
    "        'r1_k5_s22_e6_32_o64_se0.25',\n",
    "        # 'r3_k3_s22_e6_i40_o80_se0.25',\n",
    "        # 'r3_k5_s11_e6_i80_o112_se0.25',\n",
    "        # 'r4_k5_s22_e6_i112_o192_se0.25',\n",
    "        # 'r1_k3_s11_e6_i192_o320_se0.25',\n",
    "        # 'r1_k3_s11_e6_i24_o48_se0.25',\n",
    "    ]\n",
    "    blocks_args = BlockDecoder.decode(blocks_args)\n",
    "\n",
    "    global_params = GlobalParams(\n",
    "        batch_norm_momentum=0.99,\n",
    "        batch_norm_epsilon=1e-3,\n",
    "        dropout_rate=dropout_rate,\n",
    "        drop_connect_rate=drop_connect_rate,\n",
    "        # data_format='channels_last',  # removed, this is always true in PyTorch\n",
    "        num_classes=num_classes,\n",
    "        width_coefficient=width_coefficient,\n",
    "        depth_coefficient=depth_coefficient,\n",
    "        depth_divisor=8,\n",
    "        min_depth=None,\n",
    "        image_size=image_size,\n",
    "    )\n",
    "\n",
    "    return blocks_args, global_params\n",
    "\n",
    "blocks_args, global_params = efficientnet(width_coefficient=1.0, depth_coefficient=1.0, dropout_rate=0.7, image_size=[263, 15])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _encode_block_string(block):\n",
    "    \"\"\"Encodes a block to a string.\"\"\"\n",
    "    args = [\n",
    "        \"r%d\" % block.num_repeat,\n",
    "        \"k%d\" % block.kernel_size,\n",
    "        \"s%d%d\" % (block.strides[0], block.strides[1]),\n",
    "        \"e%s\" % block.expand_ratio,\n",
    "        \"i%d\" % block.input_filters,\n",
    "        \"o%d\" % block.output_filters\n",
    "        # kernel_size is kernel size for convolution e.g. 3 x 3\n",
    "        # num_repeat specifies how many times a particular block needs to be repeated, must be greater than zero\n",
    "        # input_filters and output_filters are numbers of specified filters\n",
    "        # expand_ratio is input filter expansion ratio\n",
    "        # id_skip suggests whether to use skip connection or not\n",
    "        # se_ratio provides squeezing ratio for squeeze and excitation block\n",
    "    ]\n",
    "    if 0 < block.se_ratio <= 1:\n",
    "        args.append(\"se%s\" % block.se_ratio)\n",
    "    if block.id_skip is False:\n",
    "        args.append(\"noskip\")\n",
    "    return \"_\".join(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "BlockArgs(kernel_size=(2, 2), num_repeat=1, input_filters=32, output_filters=16, expand_ratio=1, id_skip=True, stride=(2, 1), se_ratio=0.25)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def _decode_block_string(block_string):\n",
    "    \"\"\" Gets a block through a string notation of arguments. \"\"\"\n",
    "    assert isinstance(block_string, str)\n",
    "\n",
    "    ops = block_string.split('_')\n",
    "    options = {}\n",
    "    for op in ops:\n",
    "        splits = re.split(r'(\\d.*)', op)\n",
    "        if len(splits) >= 2:\n",
    "            key, value = splits[:2]\n",
    "            options[key] = value\n",
    "\n",
    "    # Check stride\n",
    "    # assert (('s' in options and len(options['s']) == 1) or\n",
    "    #         (len(options['s']) == 2 and options['s'][0] == options['s'][1]))\n",
    "    # assert (len(options['k']) < 4) and (len(options['s']) < 4), 'stride 또는 kernel_size를 조정하세요'\n",
    "    # if len(options['k'])>=2:\n",
    "    #     kernel_size = (int(options['k'][:-1]), int(options['k'][-1]))\n",
    "    # else:\n",
    "    #     kernel_size = (int(options['k']),int(options['k']))\n",
    "\n",
    "    #\n",
    "    # if len(options['s'])>=2:\n",
    "    #     stride = (int(options['s'][:-1]), int(options['s'][-1]))\n",
    "    # else:\n",
    "    #     stride = (int(options['s']), int(options['s']))\n",
    "\n",
    "    return BlockArgs(\n",
    "        kernel_size=(int(options['kh']), int(options['kw'])),\n",
    "        num_repeat=int(options['r']),\n",
    "        input_filters=int(options['i']),\n",
    "        output_filters=int(options['o']),\n",
    "        expand_ratio=int(options['e']),\n",
    "        id_skip=('noskip' not in block_string),\n",
    "        se_ratio=float(options['se']) if 'se' in options else None,\n",
    "        stride=(int(options['sh']), int(options['sw'])))\n",
    "\n",
    "_decode_block_string('r1_kh2_kw2_sh2_sw1_e1_i32_o16_se0.25')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(GlobalParams(width_coefficient=1.0, depth_coefficient=1.0, image_size=[263, 15], dropout_rate=0.7, num_classes=1, batch_norm_momentum=0.99, batch_norm_epsilon=0.001, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, include_top=None),\n [BlockArgs(num_repeat=1, kernel_size=3, stride=[1], expand_ratio=1, input_filters=32, output_filters=16, se_ratio=0.25, id_skip=True),\n  BlockArgs(num_repeat=2, kernel_size=3, stride=[2], expand_ratio=6, input_filters=16, output_filters=24, se_ratio=0.25, id_skip=True),\n  BlockArgs(num_repeat=1, kernel_size=5, stride=[2], expand_ratio=6, input_filters=24, output_filters=40, se_ratio=0.25, id_skip=True)])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_params, blocks_args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Conv2dNonPadding(nn.Conv2d):\n",
    "    \"\"\" 2D Convolutions like TensorFlow, for a fixed image size\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, image_size=None, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, **kwargs)\n",
    "        # self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2\n",
    "\n",
    "        # Calculate padding based on image size and save it\n",
    "        assert image_size is not None\n",
    "        ih, iw = image_size if type(image_size) == list else [image_size, image_size]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride if type(self.stride) == list else [self.stride, self.stride]\n",
    "        # sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        self.static_padding = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.static_padding(x)\n",
    "        x = F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "x = torch.randn((1, 1, 263, 15))\n",
    "layer = Conv2dStaticSamePadding_(in_channels=1, out_channels=8, kernel_size=(15, 1), stride=(4, 2), image_size=(263, 15))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 8, 66, 8])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(x).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def calculate_output_image_size(input_image_size, stride):\n",
    "    \"\"\"Calculates the output image size when using Conv2dSamePadding with a stride.\n",
    "       Necessary for static padding. Thanks to mannatsingh for pointing this out.\n",
    "\n",
    "    Args:\n",
    "        input_image_size (int, tuple or list): Size of input image.\n",
    "        stride (int, tuple or list): Conv2d operation's stride.\n",
    "\n",
    "    Returns:\n",
    "        output_image_size: A list [H,W].\n",
    "    \"\"\"\n",
    "    if input_image_size is None:\n",
    "        return None\n",
    "    image_height, image_width = get_width_and_height_from_size(input_image_size)\n",
    "    sh, sw = stride if type(stride) == (list) or (tuple) else [stride, stride]\n",
    "    # stride = stride if isinstance(stride, int) else stride[0]\n",
    "    image_height = int(math.ceil(image_height / sh))\n",
    "    image_width = int(math.ceil(image_width / sw))\n",
    "    return [image_height, image_width]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "bn_mom = 1 - global_params.batch_norm_momentum\n",
    "bn_eps = global_params.batch_norm_epsilon\n",
    "image_size = global_params.image_size\n",
    "Conv2d = partial(Conv2dNonPadding, image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "torch.Size([32, 1, 15, 1])\n",
      "15 1\n"
     ]
    }
   ],
   "source": [
    "# Stem\n",
    "\n",
    "in_channels = 1\n",
    "out_channels = round_filters(8, global_params)\n",
    "print(out_channels)\n",
    "_conv_stem = Conv2d(in_channels, out_channels, kernel_size=(15, 1), stride=(2, 1), bias=False)\n",
    "_bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "image_size = calculate_output_image_size(image_size, stride=(2, 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "block_args = blocks_args[0]\n",
    "input_filters=round_filters(block_args.input_filters, global_params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "32"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_filters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def encode_block_string(block):\n",
    "    \"\"\"Encodes a block to a string.\"\"\"\n",
    "    args = [\n",
    "        \"r%d\" % block.num_repeat,\n",
    "        \"k%d\" % block.kernel_size,\n",
    "        \"s%d%d\" % (block.strides[0], block.strides[1]),\n",
    "        \"e%s\" % block.expand_ratio,\n",
    "        \"i%d\" % block.input_filters,\n",
    "        \"o%d\" % block.output_filters\n",
    "        # kernel_size is kernel size for convolution e.g. 3 x 3\n",
    "        # num_repeat specifies how many times a particular block needs to be repeated, must be greater than zero\n",
    "        # input_filters and output_filters are numbers of specified filters\n",
    "        # expand_ratio is input filter expansion ratio\n",
    "        # id_skip suggests whether to use skip connection or not\n",
    "        # se_ratio provides squeezing ratio for squeeze and excitation block\n",
    "    ]\n",
    "    if 0 < block.se_ratio <= 1:\n",
    "        args.append(\"se%s\" % block.se_ratio)\n",
    "    if block.id_skip is False:\n",
    "        args.append(\"noskip\")\n",
    "    return \"_\".join(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def decode(string_list):\n",
    "    \"\"\"\n",
    "    Decodes a list of string notations to specify blocks inside the network.\n",
    "    :param string_list: a list of strings, each string is a notation of block\n",
    "    :return: a list of BlockArgs namedtuples of block args\n",
    "    \"\"\"\n",
    "    assert isinstance(string_list, list)\n",
    "    blocks_args = []\n",
    "    for block_string in string_list:\n",
    "        blocks_args.append(_decode_block_string(block_string))\n",
    "    return blocks_args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def _decode_block_string(block_string):\n",
    "    \"\"\"Gets a block through a string notation of arguments.\"\"\"\n",
    "    assert isinstance(block_string, str)\n",
    "\n",
    "    ops = block_string.split(\"_\")\n",
    "    options = {}\n",
    "    for op in ops:\n",
    "        splits = re.split(r\"(\\d.*)\", op)\n",
    "        if len(splits) >= 2:\n",
    "            key, value = splits[:2]\n",
    "            options[key] = value\n",
    "\n",
    "    # # Check stride\n",
    "    # assert (\"s\" in options and len(options[\"s\"]) == 1) or (\n",
    "    #     len(options[\"s\"]) == 2 and options[\"s\"][0] == options[\"s\"][1]\n",
    "    # )\n",
    "\n",
    "    return BlockArgs(\n",
    "        kernel_size=(int(options[\"kh\"]), int(options[\"kw\"])),\n",
    "        num_repeat=int(options[\"r\"]),\n",
    "        input_filters=int(options[\"i\"]),\n",
    "        output_filters=int(options[\"o\"]),\n",
    "        expand_ratio=int(options[\"e\"]),\n",
    "        id_skip=(\"noskip\" not in block_string),\n",
    "        se_ratio=float(options[\"se\"]) if \"se\" in options else None,\n",
    "        stride=(int(options[\"sh\"]), int(options[\"sw\"])),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "blocks_args = [\n",
    "    \"r1_kh3_kw1_sh1_sw1_e1_i32_o16_se0.25\",\n",
    "    # \"r2_k3_s22_e6_i16_o24_se0.25\",\n",
    "    # \"r1_k5_s22_e6_i24_o40_se0.25\",\n",
    "    # 'r3_k3_s22_e6_i40_o80_se0.25',\n",
    "    # 'r3_k5_s11_e6_i80_o112_se0.25',\n",
    "    # 'r4_k5_s22_e6_i112_o192_se0.25',\n",
    "    # 'r1_k3_s11_e6_i192_o320_se0.25',\n",
    "    # 'r1_k3_s11_e6_i24_o48_se0.25',\n",
    "]\n",
    "blocks_args = decode(blocks_args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _encode_block_string(block):\n",
    "    \"\"\"Encodes a block to a string.\"\"\"\n",
    "    args = [\n",
    "        \"r%d\" % block.num_repeat,\n",
    "        \"kh%d\" % block.kernel_size[0],\n",
    "        \"s%d%d\" % (block.strides[0], block.strides[1]),\n",
    "        \"e%s\" % block.expand_ratio,\n",
    "        \"i%d\" % block.input_filters,\n",
    "        \"o%d\" % block.output_filters\n",
    "        # kernel_size is kernel size for convolution e.g. 3 x 3\n",
    "        # num_repeat specifies how many times a particular block needs to be repeated, must be greater than zero\n",
    "        # input_filters and output_filters are numbers of specified filters\n",
    "        # expand_ratio is input filter expansion ratio\n",
    "        # id_skip suggests whether to use skip connection or not\n",
    "        # se_ratio provides squeezing ratio for squeeze and excitation block\n",
    "    ]\n",
    "    if 0 < block.se_ratio <= 1:\n",
    "        args.append(\"se%s\" % block.se_ratio)\n",
    "    if block.id_skip is False:\n",
    "        args.append(\"noskip\")\n",
    "    return \"_\".join(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def encode(blocks_args):\n",
    "    \"\"\"\n",
    "    Encodes a list of BlockArgs to a list of strings.\n",
    "    :param blocks_args: a list of BlockArgs namedtuples of block args\n",
    "    :return: a list of strings, each string is a notation of block\n",
    "    \"\"\"\n",
    "    block_strings = []\n",
    "    for block in blocks_args:\n",
    "        block_strings.append(_encode_block_string(block))\n",
    "    return block_strings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "block = blocks_args[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def _encode_block_string(block):\n",
    "    \"\"\"Encodes a block to a string.\"\"\"\n",
    "    args = [\n",
    "        \"r%d\" % block.num_repeat,\n",
    "        \"kh%d\" % block.kernel_size[0],\n",
    "        \"kw%d\" % block.kernel_size[1],\n",
    "        \"sh%d\" % block.stride[0],\n",
    "        \"sw%d\" % block.stride[1],\n",
    "        # \"s%d%d\" % (block.strides[0], block.strides[1]),\n",
    "        \"e%s\" % block.expand_ratio,\n",
    "        \"i%d\" % block.input_filters,\n",
    "        \"o%d\" % block.output_filters\n",
    "        # kernel_size is kernel size for convolution e.g. 3 x 3\n",
    "        # num_repeat specifies how many times a particular block needs to be repeated, must be greater than zero\n",
    "        # input_filters and output_filters are numbers of specified filters\n",
    "        # expand_ratio is input filter expansion ratio\n",
    "        # id_skip suggests whether to use skip connection or not\n",
    "        # se_ratio provides squeezing ratio for squeeze and excitation block\n",
    "    ]\n",
    "    if 0 < block.se_ratio <= 1:\n",
    "        args.append(\"se%s\" % block.se_ratio)\n",
    "    if block.id_skip is False:\n",
    "        args.append(\"noskip\")\n",
    "    return \"_\".join(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "'r1_kh3_kw1_sh1_sw1_e1_i32_o16_se0.25'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_encode_block_string(blocks_args[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "blocks = nn.ModuleList([])\n",
    "for block_args in blocks_args:\n",
    "\n",
    "    # Update block input and output filters based on depth multiplier.\n",
    "    block_args = block_args._replace(\n",
    "        input_filters=round_filters(block_args.input_filters, global_params),\n",
    "        # input_filters=8,\n",
    "        output_filters=round_filters(block_args.output_filters, global_params),\n",
    "        num_repeat=round_repeats(block_args.num_repeat, global_params)\n",
    "    )\n",
    "\n",
    "    # The first block needs to take care of stride and filter size increase.\n",
    "    self._blocks.append(MBConvBlock(block_args, self._global_params, image_size=image_size))\n",
    "    image_size = calculate_output_image_size(image_size, block_args.stride)\n",
    "    if block_args.num_repeat > 1:  # modify block_args to keep same output size\n",
    "        block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "    for _ in range(block_args.num_repeat - 1):\n",
    "        self._blocks.append(MBConvBlock(block_args, self._global_params, image_size=image_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "[BlockArgs(num_repeat=1, kernel_size=3, stride=[1], expand_ratio=1, input_filters=32, output_filters=16, se_ratio=0.25, id_skip=True),\n BlockArgs(num_repeat=2, kernel_size=3, stride=[2], expand_ratio=6, input_filters=16, output_filters=24, se_ratio=0.25, id_skip=True),\n BlockArgs(num_repeat=1, kernel_size=5, stride=[2], expand_ratio=6, input_filters=24, output_filters=40, se_ratio=0.25, id_skip=True)]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
